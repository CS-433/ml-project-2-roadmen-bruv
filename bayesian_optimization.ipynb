{"cells":[{"cell_type":"markdown","metadata":{"id":"0WleOKL9cg2B"},"source":["# Bayesian optimization\n","This file implements our bayesian optimization method. Run this to find the best parameters, and then use them in the run.ipynb!"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwhp_Q-Fcg2G","executionInfo":{"status":"ok","timestamp":1703113514000,"user_tz":-60,"elapsed":32102,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"54e2308c-a547-46bb-bf43-61ce2a901332"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDbF0ynocg2I","executionInfo":{"status":"ok","timestamp":1703113516035,"user_tz":-60,"elapsed":2041,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"a2a6ed4e-3b60-4db0-b3c8-0528aaae8bf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/EPFL/MachineLearningMA3/ml-sub/ml-project-2-roadmen-bruv\n"]}],"source":["## Folder path to Google Drive project directory\n","victor = True\n","tomas = False\n","edwin = False\n","\n","if tomas:\n","  path_to_your_folder =  \"/content/drive/MyDrive/ML_google_colab/Project 2/submission_branch/ml-project-2-roadmen-bruv\"\n","elif victor:\n","  path_to_your_folder = \"/content/drive/MyDrive/EPFL/MachineLearningMA3/ml-sub/ml-project-2-roadmen-bruv\"\n","elif edwin:\n","  path_to_your_folder = \"/content/drive/MyDrive/ml-project-2-roadmen-bruv\"\n","\n","\n","%cd $path_to_your_folder"]},{"cell_type":"markdown","metadata":{"id":"YCCYSzSVcg2J"},"source":["## Libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"m2zI4vFncg2K","executionInfo":{"status":"ok","timestamp":1703113547689,"user_tz":-60,"elapsed":31660,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install git+https://github.com/qubvel/segmentation_models.pytorch --quiet\n","!pip install -U albumentations --quiet\n","!pip install bayesian-optimization --quiet\n","clear_output()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R0vkKNhWcg2K","executionInfo":{"status":"ok","timestamp":1703113561759,"user_tz":-60,"elapsed":14079,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch import utils as smp_utils\n","import albumentations as albu\n","\n","import sys\n","sys.path.append(\"./utils\")\n","sys.path.append(\"./helpers\")\n","\n","import matplotlib.image as mpimg\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import torch\n","\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","import pandas as pd\n","\n","## Utils\n","from dataset import Dataset, get_preprocessing\n","\n","## Helpers\n","from mask_to_submission import masks_to_submission\n","\n","## Custom F1 score\n","from f1scorepatch import F1ScorePatch\n","\n","## Bayesian optimization library\n","from bayes_opt import BayesianOptimization\n","\n","## To empty cache\n","import gc ###\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"dD8vRiXrcg2L"},"source":["## Command board\n","**NB:** We run a dummy instance to show that our framework works, which explains the low number of epochs. The results showed in the report were trained using 40 epochs and data augmentation."]},{"cell_type":"code","execution_count":49,"metadata":{"id":"eh26yjXJcg2N","executionInfo":{"status":"ok","timestamp":1703114915566,"user_tz":-60,"elapsed":3,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["PARAMS = {\n","  'MODELS' : [\"Unet\"], # Available : \"Unet\",\"DeepLabV3\",\"FPN\", \"UnetPlusPlus\"\n","  'ENCODER' : 'resnet34',\n","  'ENCODER_WEIGHTS' : 'imagenet',\n","  'NB_EPOCHS' : 5\n","  ,\n","  'ACTIVATION' : 'sigmoid', # could be None for logits or 'softmax2d' for multiclass segmentation,\n","  'DATA_AUGMENTATION' : False, #choose whether to train with augmented dataset,\n","  'LOSS_TYPE': \"dice\", # Possible: [\"dice\", \"tversky\", \"custom\"]\n","  'METRIC_TYPE': \"fscore\", # Possible: [\"custom\", \"fscore\"]\n","  'CLASSES' : ['road'],\n","}"]},{"cell_type":"markdown","metadata":{"id":"C9-7EZgxcg2O"},"source":["## Data importation"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"rZRMhHaqcg2P","executionInfo":{"status":"ok","timestamp":1703114915567,"user_tz":-60,"elapsed":3,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["## Importing preprocessing fonction\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(PARAMS[\"ENCODER\"], PARAMS[\"ENCODER_WEIGHTS\"])\n","\n","#Defining folder paths\n","PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented/raw/images/\"\n","PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented/raw/masks/\"\n","PATH_VAL_IMG_RAW = \"./data/data_validation/raw/images/\"\n","PATH_VAL_MASK_RAW = \"./data/data_validation/raw/masks/\"\n","PATH_TR_IMG_AUG = \"./data/data_train_augmented/images/\"\n","PATH_TR_MASK_AUG = \"./data/data_train_augmented/masks/\"\n","PATH_VAL_IMG = \"./data/data_validation/images/\"\n","PATH_VAL_MASK = \"./data/data_validation/masks/\"\n","\n","\n","#change paths for the training and validation datasets depending on wether we want data augmentation or not\n","if PARAMS[\"DATA_AUGMENTATION\"]:\n","  training_path_img = PATH_TR_IMG_AUG\n","  training_path_mask = PATH_TR_MASK_AUG\n","  validation_path_img = PATH_VAL_IMG\n","  validation_path_mask = PATH_VAL_MASK\n","else:\n","  training_path_img = PATH_TR_IMG_AUG_RAW\n","  training_path_mask = PATH_TR_MASK_AUG_RAW\n","  validation_path_img = PATH_VAL_IMG_RAW\n","  validation_path_mask = PATH_VAL_MASK_RAW\n","\n","#create training and validation datasets\n","train_dataset = Dataset(\n","    training_path_img,\n","    training_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"])\n","\n","\n","valid_dataset = Dataset(\n","    validation_path_img,\n","    validation_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"],\n",")\n","\n","#create the loaders for both datasets\n","train_loader = DataLoader(train_dataset, batch_size=30, shuffle=False)\n","valid_loader = DataLoader(valid_dataset, batch_size=20, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"33ARBI0lcg2R"},"source":["## Bayesian optimization"]},{"cell_type":"markdown","metadata":{"id":"QopWpt37cg2R"},"source":["### Training function\n","\n","This is the exact same training process that can be found in run.ipynb, but adapted into a function to allow interaction with the [BayesianOptimization library](https://github.com/bayesian-optimization/BayesianOptimization)."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"7AqeY_U4cg2R","executionInfo":{"status":"ok","timestamp":1703114915567,"user_tz":-60,"elapsed":3,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["def model_training(_alpha=0.5, _beta=0.5, _gamma=0.75, _lr=1e-4, print_logs=False):\n","    # Ensure that the model and optimizer are reinitialized\n","    best_validation_scores = []\n","    models = None\n","    optimizer = None\n","    # Instantiating a new model for each iteration\n","    models = [[smp.create_model(model_name, encoder_name=PARAMS[\"ENCODER\"], encoder_weights=PARAMS[\"ENCODER_WEIGHTS\"], in_channels=3, classes=1), model_name] for model_name in PARAMS[\"MODELS\"]]\n","\n","    # Defining the loss\n","    loss_fn = smp.losses.tversky.TverskyLoss(mode='binary', alpha=_alpha, beta=_beta, gamma=_gamma)\n","    loss_fn.__name__ = 'Tversky_Loss'\n","    loss_name = 'Tversky_Loss'\n","\n","    # Defining the metric\n","    metrics_training = [smp_utils.metrics.Fscore()]\n","    metrics_validation = [smp_utils.metrics.Fscore(), F1ScorePatch(activation='sigmoid')]\n","    metric_name_val = \"f1_score_patch\" # can also pick \"fscore\"\n","\n","    # Train models for NB_EPOCHS\n","    for model, model_name in models:\n","        optimizer = torch.optim.Adam([\n","            dict(params=model.parameters(), lr=_lr),\n","        ])\n","\n","        train_epoch = smp.utils.train.TrainEpoch(\n","            model,\n","            loss=loss_fn,\n","            metrics=metrics_training,\n","            optimizer=optimizer,\n","            device=\"cuda\",\n","            verbose=print_logs,\n","        )\n","\n","        valid_epoch = smp.utils.train.ValidEpoch(\n","            model,\n","            loss=loss_fn,\n","            metrics=metrics_validation,\n","            device=\"cuda\",\n","            verbose=print_logs,\n","        )\n","\n","        max_score = 0\n","        train_loss_array = []\n","        validation_loss_array = []\n","        validation_fscore_array = []\n","\n","        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=print_logs)\n","\n","        for i in range(0, PARAMS[\"NB_EPOCHS\"]):\n","            if print_logs:\n","                print('\\nEpoch: {}'.format(i))\n","            train_logs = train_epoch.run(train_loader)\n","            valid_logs = valid_epoch.run(valid_loader)\n","\n","            train_loss_array.append(train_logs[loss_name])\n","            validation_loss_array.append(valid_logs[loss_name])\n","            validation_fscore_array.append(valid_logs[metric_name_val])\n","\n","            scheduler.step(valid_logs[metric_name_val])\n","\n","            # Only saving the model if the validation metric increases\n","            if max_score < valid_logs[metric_name_val]:\n","                max_score = valid_logs[metric_name_val]\n","                if print_logs:\n","                    print('New iteration best is found!')\n","\n","        best_validation_scores.append(max_score)\n","        if print_logs:\n","            print(best_validation_scores)\n","            print(max(best_validation_scores))\n","\n","        # Ensure that the model is deleted from the GPU\n","        del model, optimizer\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    return max(best_validation_scores)\n"]},{"cell_type":"markdown","metadata":{"id":"1ZuwxBHTcg2S"},"source":["### BO function"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"2t-MMkKrcg2S","executionInfo":{"status":"ok","timestamp":1703114917439,"user_tz":-60,"elapsed":3,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}}},"outputs":[],"source":["def bayesian_optimization(preloaded_points = []):\n","    \"\"\"\n","    Perform Bayesian optimization to find the best set of parameters for model training.\n","\n","    Args:\n","        preloaded_points (list, optional): List of preloaded points to initialize the optimization process.\n","                                           Each point should be a dictionary with 'params' and 'target' keys.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","\n","    # Define the bounds for each parameter\n","    pbounds = {\n","        '_alpha': (0.3, 0.7),  # Range for alpha\n","        '_beta': (0.3, 0.7),   # Range for beta\n","        '_gamma': (0.5, 2),    # Range for gamma\n","        '_lr': (1e-5, 1e-2)    # Range for learning rate\n","    }\n","\n","    optimizer = BayesianOptimization(\n","        f=model_training,\n","        pbounds=pbounds,\n","        random_state=1,\n","    )\n","\n","    # Register preloaded points\n","    for point in preloaded_points:\n","        optimizer.register(params=point['params'], target=point['target'])\n","\n","    # Perform optimization\n","    optimizer.maximize(\n","        init_points=2,  # Number of random initial points\n","        n_iter=2,      # Number of iterations\n","    )\n","\n","    # Print the best parameters found\n","    print(\"Best Parameters: \", optimizer.max['params'])"]},{"cell_type":"markdown","metadata":{"id":"oMme5y6Dcg2S"},"source":["### Optimization\n","**NB:** The optimization results shown in the report are not displayed here as they were very long to run. Instead we run a dummy instance to show that our framework is functionnal.\n","\n","There is also a possibilty to import previous results if ever we want to add additional iterations to improve our optimum."]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmtV3tE0cg2S","executionInfo":{"status":"ok","timestamp":1703115031595,"user_tz":-60,"elapsed":113581,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"439253f0-1f7c-4843-fc8b-9984ff27af53"},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   |  _alpha   |   _beta   |  _gamma   |    _lr    |\n","-------------------------------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.4305   \u001b[0m | \u001b[0m0.4668   \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.5002   \u001b[0m | \u001b[0m0.00303  \u001b[0m |\n","| \u001b[95m2        \u001b[0m | \u001b[95m0.539    \u001b[0m | \u001b[95m0.3587   \u001b[0m | \u001b[95m0.3369   \u001b[0m | \u001b[95m0.7794   \u001b[0m | \u001b[95m0.003462 \u001b[0m |\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.4315   \u001b[0m | \u001b[0m0.3031   \u001b[0m | \u001b[0m0.3647   \u001b[0m | \u001b[0m1.564    \u001b[0m | \u001b[0m0.00765  \u001b[0m |\n","| \u001b[0m4        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.477    \u001b[0m | \u001b[0m0.4654   \u001b[0m | \u001b[0m1.322    \u001b[0m | \u001b[0m0.007445 \u001b[0m |\n","=========================================================================\n","Best Parameters:  {'_alpha': 0.3587023563268452, '_beta': 0.3369354379075191, '_gamma': 0.7793903170665064, '_lr': 0.0034621516631600474}\n"]}],"source":["bayesian_optimization()"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}