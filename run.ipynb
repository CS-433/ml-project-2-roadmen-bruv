{"cells":[{"cell_type":"markdown","source":["# **Machine Learning: Project 2 - Road segmentation**\n","\n","---"],"metadata":{"id":"dv9LvNvH0UwW"}},{"cell_type":"markdown","source":["# I) Setup"],"metadata":{"id":"lb1NwAeSlGYH"}},{"cell_type":"markdown","source":["## Drive/repository access"],"metadata":{"id":"eTqRcJFglEQw"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24958,"status":"ok","timestamp":1702044799050,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"},"user_tz":-60},"id":"AMAsrtnMBVG1","outputId":"3c1870ec-fbed-40f8-d2fe-aa8fe6c2059d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NHorZ12T7Oyj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702044799051,"user_tz":-60,"elapsed":5,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}},"outputId":"9d327c83-183a-4658-c555-35f2ebfcb266"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ml-project-2-roadmen-bruv\n"]}],"source":["victor = False\n","tomas = False\n","edwin = True\n","\n","if tomas:\n","  path_to_your_folder =  \"/content/drive/MyDrive/ML_google_colab/Project 2/ml-project-2-roadmen-bruv\"\n","elif victor:\n","  path_to_your_folder = \"/content/drive/MyDrive/EPFL/MachineLearningMA3/ml-project-2-roadmen-bruv\"\n","elif edwin:\n","  path_to_your_folder = \"/content/drive/MyDrive/ml-project-2-roadmen-bruv\"\n","\n","%cd $path_to_your_folder"]},{"cell_type":"markdown","source":["## Libraries installation and imports"],"metadata":{"id":"D4romuDEk8Qe"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"szGMCcPK8F8V","executionInfo":{"status":"ok","timestamp":1702044799051,"user_tz":-60,"elapsed":3,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["from IPython.display import clear_output\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"32osBUOECMEs","executionInfo":{"status":"ok","timestamp":1702044827823,"user_tz":-60,"elapsed":28775,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["!pip install git+https://github.com/qubvel/segmentation_models.pytorch --quiet\n","!pip install -U albumentations --quiet\n","clear_output()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rslVf64mG26i","executionInfo":{"status":"ok","timestamp":1702044843750,"user_tz":-60,"elapsed":15930,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch import utils as smp_utils\n","import albumentations as albu\n","\n","import sys\n","sys.path.append(\"./utils\")\n","sys.path.append(\"./helpers\")\n","\n","import matplotlib.image as mpimg\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import torch\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","from PIL import Image\n","import pandas as pd\n","from save_training_results import save_results\n","from mask_to_submission import masks_to_submission\n","from data_augmentation import load_img_training, split_keys, store_images, resize_augment_store_dataset\n","\n","## For custom\n","import torch.nn.functional as F\n","from torch.nn.modules.loss import _Loss\n","from typing import Optional, List\n","import torch.nn as nn\n","import segmentation_models_pytorch.utils.base as base\n","import segmentation_models_pytorch.utils.functional as F\n","from segmentation_models_pytorch.base.modules import Activation\n","\n","## For submission\n","from torchvision.transforms.functional import to_pil_image, to_tensor"]},{"cell_type":"code","source":["import gc ###\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"HTJWG0RgNpcr","executionInfo":{"status":"ok","timestamp":1702044844506,"user_tz":-60,"elapsed":766,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# II) Model definition"],"metadata":{"id":"t7hdYfDMlSND"}},{"cell_type":"markdown","source":["## Command board"],"metadata":{"id":"XQor9tdyk-wl"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"fuY2yG0t-OYI","executionInfo":{"status":"ok","timestamp":1702044844506,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["PARAMS = {\n","  'MODELS' : [\"Unet\"], # Available : \"Unet\",\"DeepLabV3\",\"FPN\", \"UnetPlusPlus\"\n","  'ENCODER' : 'resnet34',\n","  'ENCODER_WEIGHTS' : 'imagenet',\n","  'NB_EPOCHS' : 1,\n","  'ACTIVATION' : 'sigmoid', # could be None for logits or 'softmax2d' for multiclass segmentation,\n","  'DATA_AUGMENTATION' : True, #choose whether the data is augmented to 900 images or use original dataset of 100 images,\n","  'CLASSES' : ['road'],\n","}"]},{"cell_type":"code","source":["# Default parameters for various parts\n","foreground_threshold = 0.5  # Threshold for determining foreground vs background\n","\n","loss_type = \"dice\" # Possible: [\"dice\", \"tversky\", \"custom\"]\n","metric_type = \"fscore\" # Possible: [\"custom\", \"fscore\"]\n","\n","#For custom, changes balance between pixel and patch\n","w_pix = 0\n","w_patch = 1"],"metadata":{"id":"Waw9mJIlmuYD","executionInfo":{"status":"ok","timestamp":1702044844506,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"VG8fw7Xz_g2M","executionInfo":{"status":"ok","timestamp":1702044844506,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["#Creates the necessary folders for saving results\n","model_weights_folder = './submissions/models/'\n","os.makedirs(model_weights_folder, exist_ok=True)\n","\n","SUBMISSION_NAME = \"submission_\" + \"test_run/\"\n","submission_folder = './submissions/' + SUBMISSION_NAME\n","os.makedirs(submission_folder, exist_ok=True)"]},{"cell_type":"markdown","source":["## II.a) Dataset class"],"metadata":{"id":"_dSnxrzXlYgV"}},{"cell_type":"code","source":["class Dataset(BaseDataset):\n","  CLASSES = ['non-road', 'road']\n","\n","  def __init__(self, images_dir, masks_dir=None, classes=None, augmentation=None, preprocessing=None, plot = False):\n","      if masks_dir == None:\n","        self.ids = range(1, 51)\n","        self.images_path = [os.path.join(images_dir, f'test_{idx}/',f'test_{idx}.png') for idx in self.ids]\n","      else:\n","        self.ids = os.listdir(images_dir)\n","        self.images_path = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","      self.masks_path = [os.path.join(masks_dir, image_id) for image_id in self.ids] if masks_dir is not None else None\n","\n","      # convert str names to class values on masks\n","      if classes is not None:\n","          self.class_values = [self.CLASSES.index(cls.lower())*255 for cls in classes]\n","\n","      self.augmentation = augmentation ###plus besoin ?\n","      self.preprocessing = preprocessing\n","      # self.preprocessing = None\n","      self.plot = plot\n","\n","  def __getitem__(self, i):\n","\n","      # read data\n","      image = cv2.imread(self.images_path[i])\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      height, width, channel = image.shape\n","      if (height % 32) or (width % 32):\n","          image = cv2.resize(image, (416, 416)) ###\n","\n","      # initialize mask as None\n","      mask = None\n","\n","      if self.masks_path == None:\n","        if self.augmentation: ###plus besoin ?\n","          sample = self.augmentation(image=image)\n","          image = sample['image']\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image)\n","            image = sample['image']\n","        return self.images_path[i], image\n","\n","      else:\n","        mask = cv2.imread(self.masks_path[i], 0)\n","        if (height % 32) or (width % 32): ###\n","            mask = cv2.resize(mask, (416, 416))\n","            mask[mask<=120] = 0 #pixel value {0, 255}\n","            mask[mask>120] = 255\n","        masks = [(mask == v) for v in self.class_values]\n","        mask = np.stack(masks, axis=-1).astype('float')\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","        if self.preprocessing:\n","              sample = self.preprocessing(image=image, mask=mask)\n","              image, mask = sample['image'], sample['mask']\n","        return image, mask\n","\n","  def __len__(self):\n","      return len(self.ids)"],"metadata":{"id":"SH8hhzxoqTgm","executionInfo":{"status":"ok","timestamp":1702044844916,"user_tz":-60,"elapsed":412,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## II.b) Preprocessing"],"metadata":{"id":"vZ_X5BXZljDe"}},{"cell_type":"markdown","source":["### Data aug"],"metadata":{"id":"cIVkMNXdnf2N"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"_TOoDIgZrYKY","executionInfo":{"status":"ok","timestamp":1702044844917,"user_tz":-60,"elapsed":3,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["# Create folders for data augmentation\n","if False:\n","  %mkdir data/data_train_augmented\n","  %mkdir data/data_train_augmented/images/\n","  %mkdir data/data_train_augmented/masks/\n","  %mkdir data/data_train_augmented/raw/\n","  %mkdir data/data_train_augmented/raw/images/\n","  %mkdir data/data_train_augmented/raw/masks/\n","  %mkdir data/data_validation\n","  %mkdir data/data_validation/images/\n","  %mkdir data/data_validation/masks/\n","  %mkdir data/data_validation/raw/\n","  %mkdir data/data_validation/raw/images/\n","  %mkdir data/data_validation/raw/masks/\n","\n","  # Load images and masks from dataset\n","  PATH_IMG_TRAIN = \"./data/training/images/\"\n","  PATH_MASK_TRAIN = \"./data/training/groundtruth/\"\n","  img_train, mask_train = load_img_training(PATH_IMG_TRAIN, PATH_MASK_TRAIN)\n","  key_list = list(img_train.keys())\n","  key_list.sort()\n","\n","  # Split the images for training/validation (+ store)\n","  training_ratio = 0.8\n","  seed = 1\n","  train_keys, val_keys = split_keys(np.array(key_list), training_ratio=training_ratio, seed=seed)\n","\n","  PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented/raw/images/\"\n","  PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented/raw/masks/\"\n","  PATH_VAL_IMG_RAW = \"./data/data_validation/raw/images/\"\n","  PATH_VAL_MASK_RAW = \"./data/data_validation/raw/masks/\"\n","\n","  store_images(img_train, train_keys, PATH_TR_IMG_AUG_RAW)\n","  store_images(mask_train, train_keys, PATH_TR_MASK_AUG_RAW)\n","  store_images(img_train, val_keys, PATH_VAL_IMG_RAW)\n","  store_images(mask_train, val_keys, PATH_VAL_MASK_RAW)\n","\n","  MASK_THRESHOLD = 120\n","  SIZE_X = 416 #divisible by 32\n","  SIZE_Y = 416 #divisible by 32\n","  PATH_TR_IMG_AUG = \"./data/data_train_augmented/images/\"\n","  PATH_TR_MASK_AUG = \"./data/data_train_augmented/masks/\"\n","  PATH_VAL_IMG = \"./data/data_validation/images/\"\n","  PATH_VAL_MASK = \"./data/data_validation/masks/\"\n","\n","  # Load validation images and resize\n","  img_val_raw, mask_val_raw = load_img_training(PATH_VAL_IMG_RAW, PATH_VAL_MASK_RAW)\n","  keys_val = list(img_val_raw.keys())\n","  resize_augment_store_dataset(img_val_raw, mask_val_raw, keys_val, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_VAL_IMG, PATH_VAL_MASK, augment=False)\n","\n","  # Load training images, resize and augment using geometric transformation (+ store)\n","  img_tr_raw, mask_tr_raw = load_img_training(PATH_TR_IMG_AUG_RAW, PATH_TR_MASK_AUG_RAW)\n","  keys_tr = list(img_tr_raw.keys())\n","  resize_augment_store_dataset(img_tr_raw, mask_tr_raw, keys_tr, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_TR_IMG_AUG, PATH_TR_MASK_AUG, augment=True)"]},{"cell_type":"markdown","source":["### Normalization"],"metadata":{"id":"mtj1DfhcniOd"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"MEoz5JEpaykY","executionInfo":{"status":"ok","timestamp":1702044844917,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["def get_preprocessing(preprocessing_fn):\n","    \"\"\"Construct preprocessing transform\n","\n","    Args:\n","        preprocessing_fn (callbale): data normalization function\n","            (can be specific for each pretrained neural network)\n","    Return:\n","        transform: albumentations.Compose\n","\n","    \"\"\"\n","\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)\n","\n","def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')"]},{"cell_type":"markdown","source":["## II.c) Dataset importation"],"metadata":{"id":"oX8tJT0jnqSO"}},{"cell_type":"code","source":["## Importing pre processing\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(PARAMS[\"ENCODER\"], PARAMS[\"ENCODER_WEIGHTS\"])"],"metadata":{"id":"a_VBP_KYtM2j","executionInfo":{"status":"ok","timestamp":1702044844917,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"1CHZmMQaaykZ","executionInfo":{"status":"ok","timestamp":1702044852151,"user_tz":-60,"elapsed":7236,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented/raw/images/\"\n","PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented/raw/masks/\"\n","PATH_VAL_IMG_RAW = \"./data/data_validation/raw/images/\"\n","PATH_VAL_MASK_RAW = \"./data/data_validation/raw/masks/\"\n","PATH_TR_IMG_AUG = \"./data/data_train_augmented/images/\"\n","PATH_TR_MASK_AUG = \"./data/data_train_augmented/masks/\"\n","PATH_VAL_IMG = \"./data/data_validation/images/\"\n","PATH_VAL_MASK = \"./data/data_validation/masks/\"\n","\n","\n","#change paths for the training and validation datasets depending on wether we want data augmentation or not\n","if PARAMS[\"DATA_AUGMENTATION\"]:\n","  training_path_img = PATH_TR_IMG_AUG\n","  training_path_mask = PATH_TR_MASK_AUG\n","  validation_path_img = PATH_VAL_IMG\n","  validation_path_mask = PATH_VAL_MASK\n","else:\n","  training_path_img = PATH_TR_IMG_AUG_RAW\n","  training_path_mask = PATH_TR_MASK_AUG_RAW\n","  validation_path_img = PATH_VAL_IMG_RAW\n","  validation_path_mask = PATH_VAL_MASK_RAW\n","\n","#create training and validation datasets\n","train_dataset = Dataset(\n","    training_path_img,\n","    training_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"])\n","\n","\n","valid_dataset = Dataset(\n","    validation_path_img,\n","    validation_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"],\n",")\n","\n","#create the loaders for both datasets\n","train_loader = DataLoader(train_dataset, batch_size=30, shuffle=False)\n","valid_loader = DataLoader(valid_dataset, batch_size=20, shuffle=False)\n","\n"]},{"cell_type":"markdown","source":["## II.d) Loss and evaluation metrics"],"metadata":{"id":"3RT_9a1gnzOO"}},{"cell_type":"markdown","source":["### Patch based Loss and evaluation metrics\n"],"metadata":{"id":"xNLXJTNEn91d"}},{"cell_type":"code","source":["class F1score_patch(smp.utils.base.Metric):\n","    def __init__(self, threshold=0.5, activation=None, patch_thr=0.25, patch_size=16, **kwargs):\n","        super().__init__(**kwargs)\n","        self.threshold = threshold\n","        self.activation = smp.base.modules.Activation(activation)\n","        self.patch_thr = patch_thr\n","        self.patch_size = patch_size\n","\n","    def forward(self, y_pr, y_gt):  # pr => predicted, gt => groundtruth\n","        y_pr = self.activation(y_pr)\n","        y_pr = (y_pr > self.threshold).float()  # value 0.0 or 1.0\n","\n","        y_gt = self.activation(y_gt)\n","        y_gt = (y_gt > self.threshold).float()  # value 0.0 or 1.0\n","\n","        batch_size, nb_channels, height, width = y_pr.size()\n","\n","        y_pr_patch_tensor = torch.zeros(batch_size, nb_channels, height//self.patch_size, width//self.patch_size)  # N, C, H, W\n","        y_gt_patch_tensor = torch.zeros(batch_size, nb_channels, height//self.patch_size, width//self.patch_size)\n","\n","        for y in range(0, height, self.patch_size):\n","            for x in range(0, width, self.patch_size):\n","                # Extract the patches of the batch\n","                patches_pr = y_pr[..., y:y + self.patch_size, x:x + self.patch_size]\n","                patches_gt = y_gt[..., y:y + self.patch_size, x:x + self.patch_size]\n","\n","                # Iterate through each patch of the prediction\n","                for i, patch_pr in enumerate(patches_pr):\n","                    # Calculate the average of the patch\n","                    patch_avg_pr = torch.mean(patch_pr)\n","                    # Patch threshold\n","                    if patch_avg_pr > self.patch_thr:\n","                        y_pr_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 1\n","                    else:\n","                        y_pr_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 0\n","\n","                # Iterate through each patch of the groundtruth mask\n","                for i, patch_gt in enumerate(patches_gt):\n","                    # Calculate the average of the patch\n","                    patch_avg_gt = torch.mean(patch_gt)\n","                    # Patch threshold\n","                    if patch_avg_gt > self.patch_thr:\n","                        y_gt_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 1\n","                    else:\n","                        y_gt_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 0\n","\n","        tp, fp, fn, tn = smp.metrics.get_stats(y_pr_patch_tensor.to(torch.int), y_gt_patch_tensor.to(torch.int), mode='binary', threshold=self.threshold)\n","        f1_score_patch = smp.metrics.f1_score(tp=tp, fp=fp, fn=fn, tn=tn, reduction=\"micro\") #reduction=\"micro\" or \"micro-imagewise\"\n","\n","        return f1_score_patch"],"metadata":{"id":"Eh0kbVVA9Wid","executionInfo":{"status":"ok","timestamp":1702044852693,"user_tz":-60,"elapsed":544,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Define the image crop function\n","def img_crop(im, h, w):\n","    list_patches = []\n","    imgwidth = im.shape[2]\n","    imgheight = im.shape[3]\n","    for i in range(0, imgheight, h):\n","        for j in range(0, imgwidth, w):\n","            im_patch = im[:, :, j:j+w, i:i+h]\n","            list_patches.append((im_patch, i, j))\n","    return list_patches\n","\n","# Define the value to class conversion function\n","def value_to_class(v, threshold):\n","    v_mean = v.mean(dim=(2, 3))\n","    return (v_mean > threshold).float()\n","\n","def normalize_tensor(tensor):\n","    N, _, _, _ = tensor.shape\n","    normalized_tensor = torch.zeros_like(tensor)\n","    for i in range(N):\n","        min_val = tensor[i].min()\n","        max_val = tensor[i].max()\n","        normalized_tensor[i] = (tensor[i] - min_val) / (max_val - min_val)\n","    return normalized_tensor\n","\n","# Assuming predictions_tensor and ground_truths_tensor are the input 4D tensors\n","def patch_extraction(predictions_tensor, ground_truths_tensor, threshold_pred=0.25, threshold_gt=0.25, print = False, apply_sigmoid = True, patch_size = 16):\n","    N, C, H, W = predictions_tensor.shape\n","    num_patches_height = H // patch_size\n","    num_patches_width = W // patch_size\n","\n","    # Initialize tensors to hold the mean values\n","    predictions_means = torch.zeros((N, C, num_patches_height, num_patches_width))\n","    ground_truths_means = torch.zeros((N, C, num_patches_height, num_patches_width))\n","\n","    # Pass through a sigmoid to normalize data between 0 and 1\n","    predictions_tensor_pure = predictions_tensor.cpu()\n","    if apply_sigmoid:\n","        predictions_tensor = torch.sigmoid(predictions_tensor).cpu()\n","        predictions_tensor_classes = (predictions_tensor > 0.5).float()\n","\n","    # Crop the images into patches and compute the mean values\n","    # predictions_patches = img_crop(predictions_tensor, patch_size, patch_size)\n","    predictions_patches = img_crop(predictions_tensor_classes, patch_size, patch_size)\n","    ground_truths_patches = img_crop(ground_truths_tensor, patch_size, patch_size)\n","\n","    # Assign the mean values to the correct location in the tensors\n","    for patch, i, j in predictions_patches:\n","        patch_idx_height = j // patch_size\n","        patch_idx_width = i // patch_size\n","        predictions_means[:, :, patch_idx_height, patch_idx_width] = patch.mean(dim=(2, 3))\n","\n","    for patch, i, j in ground_truths_patches:\n","        patch_idx_height = j // patch_size\n","        patch_idx_width = i // patch_size\n","        ground_truths_means[:, :, patch_idx_height, patch_idx_width] = patch.mean(dim=(2, 3))\n","\n","    # Apply threshold to determine class membership\n","    predictions_classes = (predictions_means > threshold_pred).float()\n","    ground_truths_classes = (ground_truths_means > threshold_gt).float()\n","\n","    # Plot the mean images\n","    if print:\n","      fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n","      ax[0, 0].imshow(predictions_tensor_pure[0].squeeze().detach().numpy(), cmap='gray')  # Detach and convert to numpy\n","      ax[0, 0].set_title('predictions_tensor_pure')\n","      ax[0, 1].imshow(predictions_means[0].squeeze().detach().numpy(), cmap='gray')  # Detach and convert to numpy\n","      ax[0, 1].set_title('predictions_means sigmoid')\n","      ax[1, 0].imshow(predictions_classes[0].squeeze().detach().numpy(), cmap='gray')  # Detach and convert to numpy\n","      ax[1, 0].set_title('predictions_classes')\n","      ax[1, 1].imshow(ground_truths_classes[0].squeeze().detach().numpy(), cmap='gray')  # Detach and convert to numpy\n","      ax[1, 1].set_title('ground_truths_classes')\n","      plt.show()\n","\n","      # Plot histograms\n","      plt.figure(figsize=(10, 5))\n","      plt.subplot(1, 2, 1)\n","      plt.hist(predictions_means[0].cpu().squeeze().detach().numpy().flatten(), bins=50, color='blue', alpha=0.7, label='Prediction Means')\n","      plt.title('predictions_means')\n","      plt.xlabel('Pixel Values')\n","      plt.ylabel('Frequency')\n","      plt.legend()\n","\n","      plt.subplot(1, 2, 2)\n","      plt.hist(ground_truths_means[0].cpu().squeeze().detach().numpy().flatten(), bins=50, color='green', alpha=0.7, label='Ground Truth Means')\n","      plt.title('ground_truths_means')\n","      plt.xlabel('Pixel Values')\n","      plt.ylabel('Frequency')\n","      plt.legend()\n","      plt.tight_layout()\n","      plt.show()\n","\n","      # Plot histograms\n","      plt.figure(figsize=(10, 5))\n","      plt.subplot(1, 2, 1)\n","      plt.hist(predictions_tensor_pure[0].cpu().squeeze().detach().numpy().flatten(), bins=50, color='blue', alpha=0.7, label='Prediction Means')\n","      plt.title('predictions_tensor_pure')\n","      plt.xlabel('Pixel Values')\n","      plt.ylabel('Frequency')\n","      plt.legend()\n","\n","      plt.subplot(1, 2, 2)\n","      plt.hist(predictions_tensor[0].cpu().squeeze().detach().numpy().flatten(), bins=50, color='green', alpha=0.7, label='Ground Truth Means')\n","      plt.title('predictions_tensor sigmoid')\n","      plt.xlabel('Pixel Values')\n","      plt.ylabel('Frequency')\n","      plt.legend()\n","\n","      plt.tight_layout()\n","      plt.show()\n","\n","    return predictions_classes, ground_truths_classes"],"metadata":{"id":"y8bauN8IoDie","executionInfo":{"status":"ok","timestamp":1702044852693,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["## Composite metrics\n","\n","class Custom_Fscore(base.Metric):\n","    def __init__(self, beta=1, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, w_pix = 1, w_patch = 1, **kwargs):\n","        super(Custom_Fscore,self).__init__(**kwargs)\n","        self.eps = eps\n","        self.beta = beta\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","        self.w_pix = w_pix\n","        self.w_patch = w_patch\n","        print(\"Fscore w_pix: \", w_pix)\n","        print(\"Fscore w_patch: \", w_patch)\n","\n","    def forward(self, pr, gt):\n","        pr = self.activation(pr)\n","        pr_pix = pr\n","        gt_pix = gt\n","        pr_patch, gt_patch = patch_extraction(pr, gt)\n","\n","        f_score_pix = smp_utils.metrics.Fscore(\n","            beta=self.beta,\n","            eps=self.eps,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        ).forward(pr_pix, gt_pix)\n","\n","        f_score_patch = smp_utils.metrics.Fscore(\n","            beta=self.beta,\n","            eps=self.eps,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        ).forward(pr_patch, gt_patch)\n","\n","        return (self.w_pix * f_score_pix + self.w_patch * f_score_patch) / (self.w_pix + self.w_patch)"],"metadata":{"id":"82YDNrXwoDem","executionInfo":{"status":"ok","timestamp":1702044852693,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### Final model choice"],"metadata":{"id":"zR84iWPhoBTd"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"764Vgxn2ayka","executionInfo":{"status":"ok","timestamp":1702044853191,"user_tz":-60,"elapsed":500,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n","# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n","\n","# loss = smp_utils.losses.DiceLoss()\n","# metrics = [\n","#     smp_utils.metrics.IoU(threshold=0.5),\n","#     smp_utils.metrics.Fscore(),\n","# ]\n","#myinstance.__class__.__name__\n","\n","# loss_fn = CustomDiceLoss(w_pix = w_pix, w_patch = w_patch)\n","# loss_fn.__name__ = 'Custom_dice_loss'\n","\n","# metrics = [\n","#       Custom_Fscore(w_pix = w_pix, w_patch = w_patch), ]\n","\n","if loss_type == \"dice\":\n","  loss_fn = smp.losses.dice.DiceLoss(mode ='binary')\n","  loss_fn.__name__ = 'Dice_loss'\n","  loss_name = 'Dice_loss'\n","elif loss_type == \"tversky\":\n","  loss_fn = smp.losses.tversky.TverskyLoss(mode ='binary')\n","  loss_fn.__name__ = 'Tversky_Loss'\n","  loss_name = 'Tversky_Loss'\n","elif loss_type == \"custom\":\n","  print(\"Not implemented yet\")\n","\n","if metric_type == \"custom\":\n","  metrics = [\n","        Custom_Fscore(w_pix = w_pix, w_patch = w_patch), ]\n","  metric_name = \"custom__fscore\"\n","elif metric_type == \"fscore\":\n","  metrics = [\n","        smp_utils.metrics.Fscore()] #smp_utils.metrics.Fscore(), F1score_patch(activation='sigmoid')\n","  metric_name = \"fscore\"\n","  metric_name_val = \"f1score_patch\""]},{"cell_type":"markdown","source":["# III) Training"],"metadata":{"id":"l-P1uVn8mAIN"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"Cd2imBFfaykX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702044856186,"user_tz":-60,"elapsed":2998,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}},"outputId":"393a4c85-78c6-45a5-92ff-86f3dfd9a9eb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","100%|██████████| 83.3M/83.3M [00:00<00:00, 124MB/s]\n"]}],"source":["models = [[smp.create_model(model_name, encoder_name=PARAMS[\"ENCODER\"], encoder_weights = PARAMS[\"ENCODER_WEIGHTS\"], in_channels=3, classes=1),model_name] for model_name in PARAMS[\"MODELS\"]]"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"executionInfo":{"elapsed":490090,"status":"ok","timestamp":1702045346268,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"},"user_tz":-60},"id":"h2DZo52faykc","outputId":"3bba5630-bb06-492a-a3e2-0475252dc788"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unet\n","\n","Epoch: 0\n","train: 100%|██████████| 32/32 [07:44<00:00, 14.52s/it, Dice_loss - 0.6083, fscore - 0.4349]\n","valid: 100%|██████████| 1/1 [00:22<00:00, 22.32s/it, Dice_loss - 0.4556, fscore - 0.6936, f1score_patch - 0.7054]\n","{'Dice_loss': 0.45560091733932495, 'fscore': 0.6935986280441284, 'f1score_patch': 0.7053691148757935}\n","Model saved!\n","test\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# train model for NB_EPOCHS\n","for model,model_name in models:\n","  print(model_name)\n","  optimizer = torch.optim.Adam([\n","    dict(params=model.parameters(), lr=0.0001),\n","])\n","\n","  train_epoch = smp.utils.train.TrainEpoch(\n","      model,\n","      loss=loss_fn,\n","      metrics=metrics,\n","      optimizer=optimizer,\n","      device=\"cuda\",\n","      verbose=True,\n","  )\n","\n","  valid_epoch = smp.utils.train.ValidEpoch(\n","      model,\n","      loss=loss_fn,\n","      metrics=[smp_utils.metrics.Fscore(), F1score_patch(activation='sigmoid')], #metrics\n","      device=\"cuda\",\n","      verbose=True,\n","  )\n","\n","\n","  max_score = 0\n","  train_loss_array = []\n","  validation_loss_array = []\n","  validation_fscore_array = []\n","\n","\n","\n","  for i in range(0, PARAMS[\"NB_EPOCHS\"]):\n","\n","      print('\\nEpoch: {}'.format(i))\n","      train_logs = train_epoch.run(train_loader)\n","      valid_logs = valid_epoch.run(valid_loader)\n","\n","      train_loss_array.append(train_logs[loss_name])\n","      validation_loss_array.append(valid_logs[loss_name])\n","      validation_fscore_array.append(valid_logs[metric_name_val])\n","      print(valid_logs)\n","      # do something (save model, change lr, etc.)\n","      if max_score < valid_logs[metric_name_val]:\n","          max_score = valid_logs[metric_name_val]\n","          torch.save(model, model_weights_folder + 'best_model_{}.pth'.format(model_name))\n","          print('Model saved!')\n","\n","      # if i == 25:\n","          # optimizer.param_groups[0]['lr'] = 1e-5\n","          # print('Decrease decoder learning rate to 1e-5!')\n","  epochs = range(0,len(train_loss_array))\n","\n","  save_results(PARAMS,train_loss_array,validation_loss_array,validation_fscore_array)\n","\n","\n","  plt.figure(figsize=(10, 5))\n","  plt.plot(epochs, train_loss_array,\"o\", label='Training Loss')\n","  plt.plot(epochs, validation_loss_array,  label='Validation Loss')\n","  plt.plot(epochs, validation_fscore_array, \"o\" ,  label='Validation fscore')\n","  plt.title('Training and Validation Loss for {}'.format(model_name))\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.legend()\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gb7gjUmf17ON"},"source":["# IV) Submission\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"HBx4LAICmMHa","executionInfo":{"status":"ok","timestamp":1702045346268,"user_tz":-60,"elapsed":3,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["MODEL_NAME = \"Unet\"\n","# Modify according to model saved that you want to import\n","MODEL_PATH = model_weights_folder + f'best_model_{MODEL_NAME}.pth'\n","DEVICE ='cuda'\n","test_model = torch.load(MODEL_PATH)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Q56JyGLW17OS","executionInfo":{"status":"ok","timestamp":1702045346735,"user_tz":-60,"elapsed":2,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["test_dataset = Dataset(\n","    images_dir=\"./data/test_set_images/\",\n","    preprocessing= get_preprocessing(preprocessing_fn),\n","    classes=['road'])\n","\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"]},{"cell_type":"markdown","metadata":{"id":"YNaRNAT417OR"},"source":["### Visualization of results"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import torch\n","import os\n","\n","# Ensure the model is on the correct device and in evaluation mode\n","test_model = test_model.to(DEVICE)\n","test_model.eval()\n","activate_threshold = True\n","img_nbr = 10\n","i = 0\n","# Iterate over all batches in the test_loader\n","for batch in test_loader:\n","    i += 1\n","    with torch.no_grad():\n","        # Move input to the device where the model is\n","        input_tensors = batch[1].to(DEVICE)\n","        logits = test_model(input_tensors)\n","        pr_gts = logits.sigmoid()\n","\n","        # Since there are no ground truth masks, we only visualize the images and predictions\n","        for img_fp, pr_gt in zip(batch[0], pr_gts):  # batch[0] should contain the file paths\n","            print(img_fp)\n","            img = cv2.imread(img_fp)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img = cv2.resize(img, (416, 416))\n","\n","            # Get the prediction as a numpy array\n","            pr_gt_cpu = pr_gt.cpu().numpy().squeeze()\n","            if activate_threshold:\n","              pr_gt_cpu[pr_gt_cpu >= foreground_threshold] = 1\n","              pr_gt_cpu[pr_gt_cpu < foreground_threshold] = 0\n","            plt.figure(figsize=(10, 5))\n","\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(img)  # No need to transpose axes since img is read with cv2 and already in HWC format\n","            plt.title(\"Image\")\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(pr_gt_cpu, cmap='gray')  # Show the prediction\n","            plt.title(\"Prediction\")\n","            plt.axis(\"off\")\n","\n","            plt.show()\n","    if i == img_nbr:\n","      break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1lqmfCH9cNwYmrzJiYeDrpDM3QGrqe0C2","height":0},"id":"BM8NQpnDtEYt","executionInfo":{"status":"ok","timestamp":1702045363677,"user_tz":-60,"elapsed":16944,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}},"outputId":"333eba0f-d29f-4f6c-cf70-cd47c83af660"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Submission creation"],"metadata":{"id":"3REiwYfLnMEF"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"cBa0US5H17OW","executionInfo":{"status":"ok","timestamp":1702045413749,"user_tz":-60,"elapsed":50085,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","test_model = test_model.to(DEVICE)\n","\n","# Parameters for saving images\n","output_folder = submission_folder + 'eval_imgs/'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Iterate over the DataLoader\n","for i, (path, image) in enumerate(test_loader):\n","    # print(\"Processing image:\", i)\n","    path = path[0]\n","    with torch.no_grad():\n","        test_model.eval()\n","        # Move input to the device\n","        input_tensor = image.to(DEVICE)\n","        logits = test_model(input_tensor)\n","        # Apply sigmoid to get probabilities\n","        probabilities = torch.sigmoid(logits)\n","        # Squeeze to remove unnecessary dimensions\n","        probabilities = probabilities.squeeze(0).squeeze(0)\n","        # Apply threshold to the probabilities to binarize\n","        prediction_binarized = (probabilities > foreground_threshold).float() ### <\n","\n","        # Convert the binarized prediction to a PIL image\n","        prediction_pil = to_pil_image(prediction_binarized)\n","\n","        # Resize the PIL image to 608x608\n","        # prediction_pil_resized = prediction_pil.resize((608, 608), Image.NEAREST)\n","\n","        # Save the image\n","        image_num = path.split('/')[-1].split('_')[-1].split('.')[0]\n","        image_num = int(image_num)\n","        filename = \"test_eval_\" + '%.3d' % image_num + '.png'\n","        prediction_pil.save(os.path.join(output_folder, filename))\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"OgXcwZ4K17OX","executionInfo":{"status":"ok","timestamp":1702045415913,"user_tz":-60,"elapsed":2173,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"outputs":[],"source":["submission_filename = submission_folder + 'test_submission.csv'\n","image_filenames = []\n","for i in range(1, 51):\n","    # image_filename = 'training/groundtruth/satImage_' + '%.3d' % i + '.png'\n","    image_filename = submission_folder + 'eval_imgs/test_eval_' + '%.3d' % i + '.png'\n","    image_filenames.append(image_filename)\n","masks_to_submission(submission_filename, *image_filenames)\n"]},{"cell_type":"markdown","source":["## Visualisation predictions"],"metadata":{"id":"d_cqzcgW-6uS"}},{"cell_type":"code","source":["if False:\n","    def list_files_in_directory(directory):\n","        file_list = []\n","        for root, dirs, files in os.walk(directory):\n","            for file in files:\n","                file_list.append(os.path.join(root, file))\n","        return file_list\n","\n","    pred_path = submission_folder + \"/eval_imgs/\"\n","    pred_files = list_files_in_directory(pred_path)\n","\n","    img_path = \"./data/test_set_images/\"\n","    img_files = list_files_in_directory(img_path)\n","    img_files = sorted(img_files, key=lambda x: int(os.path.basename(x)[5:-4]))\n","    img_mask_list = []\n","    for i, pred_file in enumerate(pred_files):\n","        img = cv2.imread(img_files[i], cv2.IMREAD_COLOR)\n","        pred_mask = cv2.imread(pred_file, cv2.IMREAD_GRAYSCALE)\n","\n","        # Create a semi-transparent green mask\n","        alpha = 0.7\n","        red_mask = np.zeros_like(img)\n","        for (i,j), value in np.ndenumerate(pred_mask):\n","            if value == 255:\n","                red_mask[i,j] = [0, 255, 0]\n","\n","        # Combine image and the green mask\n","        result = cv2.addWeighted(img, 1, red_mask, alpha, 0)\n","        img_mask_list.append(result)\n","    # Set the number of images per row\n","    images_per_row = 2\n","\n","    # Calculate the number of rows needed\n","    num_rows = (len(img_mask_list) + images_per_row - 1) // images_per_row\n","\n","    # Create a single row of subplots\n","    fig, axs = plt.subplots(1, images_per_row, figsize=(10, 5))\n","\n","    # Loop through files and plot images\n","    for i, img in enumerate(img_mask_list):\n","        axs[i % images_per_row].imshow(img)\n","        axs[i % images_per_row].axis('off')\n","\n","        # If last image in the row, create a new row of subplots\n","        if (i + 1) % images_per_row == 0:\n","            plt.show()\n","            if i + 1 < len(img_mask_list):\n","                fig, axs = plt.subplots(1, images_per_row, figsize=(10, 5))\n","\n","    plt.show()"],"metadata":{"id":"e52giDyD-47e","executionInfo":{"status":"ok","timestamp":1702045415914,"user_tz":-60,"elapsed":4,"user":{"displayName":"Edwin Bertschy","userId":"01520589558980144494"}}},"execution_count":26,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["YNaRNAT417OR"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}