{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18922,"status":"ok","timestamp":1702540826027,"user":{"displayName":"Victor","userId":"16057659027853074662"},"user_tz":-60},"id":"3y4sG-lHKe_E","outputId":"31b6cda2-32c5-4c7b-c3f2-ee0007f8b50a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1702540827871,"user":{"displayName":"Victor","userId":"16057659027853074662"},"user_tz":-60},"id":"WmFVSFcWK6Et","outputId":"0146a9b1-e03b-4813-c9dd-e7587d0b3734"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1Otvsxl8-1dcvf92GQ9nybOqsg4Z_dpEJ/ml-project-2-roadmen-bruv\n"]}],"source":["if False:\n","  %cd /content/drive/MyDrive/ml-project-2-roadmen-bruv/\n","if False:\n","  %cd \"/content/drive/MyDrive/ML_google_colab/Project 2/ml-project-2-roadmen-bruv\"\n","if True:\n","  # %cd \"/content/drive/MyDrive/EPFL/MachineLearningMA3/ml-project-2-roadmen-bruv\"\n","  %cd \"/content/drive/MyDrive/ml-project-2-roadmen-bruv\""]},{"cell_type":"markdown","metadata":{"id":"TNqreHHmKwf_"},"source":["## Libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"WfXvJfE0K9Da","executionInfo":{"status":"ok","timestamp":1702540861334,"user_tz":-60,"elapsed":33465,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["from IPython.display import clear_output\n","!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n","!pip install -U albumentations\n","!pip install bayesian-optimization\n","\n","clear_output()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zKa_2xhIHO8N","executionInfo":{"status":"ok","timestamp":1702540861334,"user_tz":-60,"elapsed":6,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["import sys\n","sys.path.append(\"./utils\")\n","sys.path.append(\"./helpers\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17511,"status":"ok","timestamp":1702540878840,"user":{"displayName":"Victor","userId":"16057659027853074662"},"user_tz":-60},"id":"kX1ECsX3Kvwy"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch import utils as smp_utils\n","\n","import matplotlib.image as mpimg\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os, sys\n","import torch\n","from PIL import Image\n","import albumentations as albu\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","from PIL import Image\n","import pandas as pd\n","from mask_to_submission import masks_to_submission\n","import utils.data_augmentation as data\n","from save_training_results import save_results\n","\n","# For alternative loss\n","import torch.nn as nn\n","import segmentation_models_pytorch.utils.base as base\n","import segmentation_models_pytorch.utils.functional as F\n","from segmentation_models_pytorch.base.modules import Activation"]},{"cell_type":"markdown","metadata":{"id":"y2B_NeONbKfZ"},"source":["# 1st network"]},{"cell_type":"markdown","metadata":{"id":"2JRA7NY-Gpil"},"source":["## Control board"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"zPHHxDoCHUcs","executionInfo":{"status":"ok","timestamp":1702541805918,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["\n","PARAMS = {\n","  'MODELS' : [\"Unet\"], # Available : \"Unet\",\"DeepLabV3\",\"FPN\", \"UnetPlusPlus\"\n","  'ENCODER' : 'resnet34',\n","  'ENCODER_WEIGHTS' : 'imagenet',\n","  'NB_EPOCHS' : 1,\n","  'ACTIVATION' : 'sigmoid', # could be None for logits or 'softmax2d' for multiclass segmentation,\n","  'DATA_AUGMENTATION' : False, #choose whether the data is augmented to 900 images or use original dataset of 100 images,\n","  'CLASSES' : ['road'],\n","}\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702541805919,"user":{"displayName":"Victor","userId":"16057659027853074662"},"user_tz":-60},"id":"cuVrmslrvqTO"},"outputs":[],"source":["\n","# Default parameters for various parts\n","foreground_threshold = 0.5  # Threshold for determining foreground vs background\n","lr = 1e-4\n","\n","# Loss and metric type\n","loss_type = \"tversky\" # Possible: [\"dice\", \"tversky\", \"custom\"]\n","metric_type = \"custom\" # custom: [\"custom\", \"fscore\"]\n","\n","#For custom, changes balance between pixel and patch\n","patch_size = 16\n","w_pix = 0\n","w_patch = 1"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702541806312,"user":{"displayName":"Victor","userId":"16057659027853074662"},"user_tz":-60},"id":"95Ene4fW3u1G"},"outputs":[],"source":["#Creates the necessary folders for saving results\n","model_weights_folder = './submissions/models/'\n","os.makedirs(model_weights_folder, exist_ok=True)\n","RUN_NAME = \"vic7_bo_vaug\"\n","SUBMISSION_NAME = \"submission_\" + RUN_NAME + \"/\"\n","submission_folder = './submissions/' + SUBMISSION_NAME\n","os.makedirs(submission_folder, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"n0T406RzWSDm"},"source":["# 0) Data aug"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"q-xnXNtvWuAn","executionInfo":{"status":"ok","timestamp":1702541806731,"user_tz":-60,"elapsed":4,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["create_aug_data_dieg = False\n","create_aug_data_vic = False\n","\n","if create_aug_data_dieg:\n","    # Create folders for data augmentation\n","    %mkdir data/data_train_augmented\n","    %mkdir data/data_train_augmented/images/\n","    %mkdir data/data_train_augmented/masks/\n","    %mkdir data/data_train_augmented/raw/\n","    %mkdir data/data_train_augmented/raw/images/\n","    %mkdir data/data_train_augmented/raw/masks/\n","    %mkdir data/data_validation\n","    %mkdir data/data_validation/images/\n","    %mkdir data/data_validation/masks/\n","    %mkdir data/data_validation/raw/\n","    %mkdir data/data_validation/raw/images/\n","    %mkdir data/data_validation/raw/masks/\n","\n","    # Load images and masks from dataset\n","    PATH_IMG_TRAIN = \"./data/training/images/\"\n","    PATH_MASK_TRAIN = \"./data/training/groundtruth/\"\n","    img_train, mask_train = load_img_training(PATH_IMG_TRAIN, PATH_MASK_TRAIN)\n","    key_list = list(img_train.keys())\n","    key_list.sort()\n","    # Split the images for training/validation (+ store)\n","    training_ratio = 0.8\n","    seed = 1\n","    train_keys, val_keys = split_keys(np.array(key_list), training_ratio=training_ratio, seed=seed)\n","    PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented/raw/images/\"\n","    PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented/raw/masks/\"\n","    PATH_VAL_IMG_RAW = \"./data/data_validation/raw/images/\"\n","    PATH_VAL_MASK_RAW = \"./data/data_validation/raw/masks/\"\n","    store_images(img_train, train_keys, PATH_TR_IMG_AUG_RAW)\n","    store_images(mask_train, train_keys, PATH_TR_MASK_AUG_RAW)\n","    store_images(img_train, val_keys, PATH_VAL_IMG_RAW)\n","    store_images(mask_train, val_keys, PATH_VAL_MASK_RAW)\n","    MASK_THRESHOLD = 120\n","    SIZE_X = 416 #divisible by 32\n","    SIZE_Y = 416 #divisible by 32\n","    PATH_TR_IMG_AUG = \"./data/data_train_augmented/images/\"\n","    PATH_TR_MASK_AUG = \"./data/data_train_augmented/masks/\"\n","    PATH_VAL_IMG = \"./data/data_validation/images/\"\n","    PATH_VAL_MASK = \"./data/data_validation/masks/\"\n","    # Load validation images and resize\n","    img_val_raw, mask_val_raw = load_img_training(PATH_VAL_IMG_RAW, PATH_VAL_MASK_RAW)\n","    keys_val = list(img_val_raw.keys())\n","    resize_augment_store_dataset(img_val_raw, mask_val_raw, keys_val, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_VAL_IMG, PATH_VAL_MASK, augment=False)\n","    # Load training images, resize and augment using geometric transformation (+ store)\n","    img_tr_raw, mask_tr_raw = load_img_training(PATH_TR_IMG_AUG_RAW, PATH_TR_MASK_AUG_RAW)\n","    keys_tr = list(img_tr_raw.keys())\n","    resize_augment_store_dataset(img_tr_raw, mask_tr_raw, keys_tr, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_TR_IMG_AUG, PATH_TR_MASK_AUG, augment=True)\n","\n","if create_aug_data_vic:\n","    # Create folders for data augmentation\n","    %mkdir data/data_train_augmented_vic3\n","    %mkdir data/data_train_augmented_vic3/images/\n","    %mkdir data/data_train_augmented_vic3/masks/\n","    %mkdir data/data_train_augmented_vic3/raw/\n","    %mkdir data/data_train_augmented_vic3/raw/images/\n","    %mkdir data/data_train_augmented_vic3/raw/masks/\n","    %mkdir data/data_validation_vic3\n","    %mkdir data/data_validation_vic3/images/\n","    %mkdir data/data_validation_vic3/masks/\n","    %mkdir data/data_validation_vic3/raw/\n","    %mkdir data/data_validation_vic3/raw/images/\n","    %mkdir data/data_validation_vic3/raw/masks/\n","\n","    # Load images and masks from dataset\n","    PATH_IMG_TRAIN = \"./data/training/images/\"\n","    PATH_MASK_TRAIN = \"./data/training/groundtruth/\"\n","    img_train, mask_train = data.load_img_training(PATH_IMG_TRAIN, PATH_MASK_TRAIN)\n","    key_list = list(img_train.keys())\n","    key_list.sort()\n","    # Split the images for training/validation (+ store)\n","    training_ratio = 0.8\n","    seed = 1\n","    train_keys, val_keys = data.split_keys(np.array(key_list), training_ratio=training_ratio, seed=seed)\n","    PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented_vic3/raw/images/\"\n","    PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented_vic3/raw/masks/\"\n","    PATH_VAL_IMG_RAW = \"./data/data_validation_vic3/raw/images/\"\n","    PATH_VAL_MASK_RAW = \"./data/data_validation_vic3/raw/masks/\"\n","    data.store_images(img_train, train_keys, PATH_TR_IMG_AUG_RAW)\n","    data.store_images(mask_train, train_keys, PATH_TR_MASK_AUG_RAW)\n","    data.store_images(img_train, val_keys, PATH_VAL_IMG_RAW)\n","    data.store_images(mask_train, val_keys, PATH_VAL_MASK_RAW)\n","    MASK_THRESHOLD = 120\n","    SIZE_X = 416 #divisible by 32\n","    SIZE_Y = 416 #divisible by 32\n","    PATH_TR_IMG_AUG = \"./data/data_train_augmented_vic3/images/\"\n","    PATH_TR_MASK_AUG = \"./data/data_train_augmented_vic3/masks/\"\n","    PATH_VAL_IMG = \"./data/data_validation_vic3/images/\"\n","    PATH_VAL_MASK = \"./data/data_validation_vic3/masks/\"\n","    # Under represented images for which to increase frequency\n","    list_keys = [\"r_satImage_023.png\", \"r_satImage_026.png\", \"r_satImage_027.png\", \"r_satImage_032.png\", \"r_satImage_033.png\", \"r_satImage_037.png\", \"r_satImage_038.png\", \"r_satImage_039.png\", \"r_satImage_040.png\", \"r_satImage_041.png\", \"r_satImage_042.png\", \"r_satImage_065.png\", \"r_satImage_069.png\", \"r_satImage_072.png\", \"r_satImage_073.png\", \"r_satImage_075.png\", \"r_satImage_077.png\", \"r_satImage_078.png\", \"r_satImage_082.png\", \"r_satImage_083.png\", \"r_satImage_087.png\", \"r_satImage_091.png\", \"r_satImage_092.png\", \"r_satImage_100.png\"]\n","\n","    # Load validation images and resize\n","    img_val_raw, mask_val_raw = data.load_img_training(PATH_VAL_IMG_RAW, PATH_VAL_MASK_RAW)\n","    keys_val = list(img_val_raw.keys())\n","    data.resize_augment_store_dataset_vic3(img_val_raw, mask_val_raw, keys_val, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_VAL_IMG, PATH_VAL_MASK, augment=False)\n","    # Load training images, resize and augment using geometric transformation (+ store)\n","    img_tr_raw, mask_tr_raw = data.load_img_training(PATH_TR_IMG_AUG_RAW, PATH_TR_MASK_AUG_RAW)\n","    keys_tr = list(img_tr_raw.keys())\n","    data.resize_augment_store_dataset_vic3(img_tr_raw, mask_tr_raw, keys_tr, SIZE_Y, SIZE_X, MASK_THRESHOLD, PATH_TR_IMG_AUG, PATH_TR_MASK_AUG, augment=True, img_spe_rot_keys = list_keys)\n"]},{"cell_type":"markdown","metadata":{"id":"AWdtDcktKl28"},"source":["# I) Model training"]},{"cell_type":"markdown","metadata":{"id":"pOyk7KcbLOZY"},"source":["## Dataset class definition"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"KG9agDX5LROQ","executionInfo":{"status":"ok","timestamp":1702541807134,"user_tz":-60,"elapsed":406,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["class Dataset(BaseDataset):\n","  CLASSES = ['road', 'unlabelled']\n","  def __init__(self, images_dir, masks_dir=None, classes=None, augmentation=None, preprocessing=None, plot = False):\n","      if masks_dir == None:\n","        self.ids = range(1, 51)\n","        self.images_fps = [os.path.join(images_dir, f'test_{idx}/',f'test_{idx}.png') for idx in self.ids]\n","      else:\n","        self.ids = os.listdir(images_dir)\n","        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","      self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids] if masks_dir is not None else None\n","\n","      # convert str names to class values on masks\n","      if classes is not None:\n","          self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n","\n","      self.augmentation = augmentation\n","      self.preprocessing = preprocessing\n","      # self.preprocessing = None\n","      self.plot = plot\n","\n","  def __getitem__(self, i):\n","\n","      # read data\n","      image = cv2.imread(self.images_fps[i])\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      height, width, channel = image.shape\n","      if (height % 32) or (width % 32):\n","          image = cv2.resize(image, (416, 416)) ###\n","      mask = None\n","\n","      if self.masks_fps == None:\n","        print(self.images_fps[i])\n","        if self.augmentation:\n","          sample = self.augmentation(image=image)\n","          image = sample['image']\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image)\n","            image = sample['image']\n","        return self.images_fps[i], image\n","\n","      else:\n","        mask = cv2.imread(self.masks_fps[i], 0)\n","        if (height % 32) or (width % 32): ###\n","            mask = cv2.resize(mask, (416, 416))\n","            mask[mask<=120] = 0 #pixel value {0, 255}\n","            mask[mask>120] = 255\n","        masks = [(mask == v) for v in self.class_values]\n","        mask = np.stack(masks, axis=-1).astype('float')\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","        if self.preprocessing:\n","              sample = self.preprocessing(image=image, mask=mask)\n","              image, mask = sample['image'], sample['mask']\n","        return image, mask\n","\n","  def __len__(self):\n","      return len(self.ids)"]},{"cell_type":"markdown","metadata":{"id":"Kc9qPEIELSUP"},"source":["## Model definitions"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"6vlao-d7LTsh","executionInfo":{"status":"ok","timestamp":1702541807135,"user_tz":-60,"elapsed":3,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["# models = [[smp.create_model(model_name, encoder_name=PARAMS[\"ENCODER\"], encoder_weights = PARAMS[\"ENCODER_WEIGHTS\"], in_channels=3, classes=1),model_name] for model_name in PARAMS[\"MODELS\"]]\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(PARAMS[\"ENCODER\"], PARAMS[\"ENCODER_WEIGHTS\"])"]},{"cell_type":"markdown","metadata":{"id":"ZkgGUCDHLf2i"},"source":["## Data importation, preprocessing and evaluation metrics def"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"3Krx2B2KNKWj","executionInfo":{"status":"ok","timestamp":1702541807750,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["def get_preprocessing(preprocessing_fn):\n","    \"\"\"Construct preprocessing transform\n","\n","    Args:\n","        preprocessing_fn (callbale): data normalization function\n","            (can be specific for each pretrained neural network)\n","    Return:\n","        transform: albumentations.Compose\n","\n","    \"\"\"\n","\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)\n","\n","def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"DJeICOs7LhjD","executionInfo":{"status":"ok","timestamp":1702541809436,"user_tz":-60,"elapsed":1239,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"outputs":[],"source":["if False:\n","  PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented/raw/images/\"\n","  PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented/raw/masks/\"\n","  PATH_VAL_IMG_RAW = \"./data/data_validation/raw/images/\"\n","  PATH_VAL_MASK_RAW = \"./data/data_validation/raw/masks/\"\n","  PATH_TR_IMG_AUG = \"./data/data_train_augmented/images/\"\n","  PATH_TR_MASK_AUG = \"./data/data_train_augmented/masks/\"\n","  PATH_VAL_IMG = \"./data/data_validation/images/\"\n","  PATH_VAL_MASK = \"./data/data_validation/masks/\"\n","\n","if True:\n","  PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented_vic3/raw/images/\"\n","  PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented_vic3/raw/masks/\"\n","  PATH_VAL_IMG_RAW = \"./data/data_validation_vic3/raw/images/\"\n","  PATH_VAL_MASK_RAW = \"./data/data_validation_vic3/raw/masks/\"\n","  PATH_TR_IMG_AUG = \"./data/data_train_augmented_vic3/images/\"\n","  PATH_TR_MASK_AUG = \"./data/data_train_augmented_vic3/masks/\"\n","  PATH_VAL_IMG = \"./data/data_validation_vic3/images/\"\n","  PATH_VAL_MASK = \"./data/data_validation_vic3/masks/\"\n","\n","#change paths for the training and validation datasets depending on wether we want data augmentation or not\n","if PARAMS[\"DATA_AUGMENTATION\"]:\n","  training_path_img = PATH_TR_IMG_AUG\n","  training_path_mask = PATH_TR_MASK_AUG\n","  validation_path_img = PATH_VAL_IMG\n","  validation_path_mask = PATH_VAL_MASK\n","else:\n","  training_path_img = PATH_TR_IMG_AUG_RAW\n","  training_path_mask = PATH_TR_MASK_AUG_RAW\n","  validation_path_img = PATH_VAL_IMG_RAW\n","  validation_path_mask = PATH_VAL_MASK_RAW\n","\n","#create training and validation datasets\n","train_dataset = Dataset(\n","    training_path_img,\n","    training_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=['road'])\n","\n","\n","valid_dataset = Dataset(\n","    validation_path_img,\n","    validation_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"],\n",")\n","\n","#create the loaders for both datasets\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n","valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"markdown","source":["## Patch based"],"metadata":{"id":"mg2N0zmhQ_AI"}},{"cell_type":"code","source":["class F1score_patch(smp.utils.base.Metric):\n","    def __init__(self, threshold=0.5, activation=None, patch_thr=0.25, patch_size=16, **kwargs):\n","        super().__init__(**kwargs)\n","        self.threshold = threshold\n","        self.activation = smp.base.modules.Activation(activation)\n","        self.patch_thr = patch_thr\n","        self.patch_size = patch_size\n","\n","    def forward(self, y_pr, y_gt):  # pr => predicted, gt => groundtruth\n","        y_pr = self.activation(y_pr)\n","        y_pr = (y_pr > self.threshold).float()  # value 0.0 or 1.0\n","\n","        y_gt = self.activation(y_gt)\n","        y_gt = (y_gt > self.threshold).float()  # value 0.0 or 1.0\n","\n","        batch_size, nb_channels, height, width = y_pr.size()\n","\n","        y_pr_patch_tensor = torch.zeros(batch_size, nb_channels, height//self.patch_size, width//self.patch_size)  # N, C, H, W\n","        y_gt_patch_tensor = torch.zeros(batch_size, nb_channels, height//self.patch_size, width//self.patch_size)\n","\n","        for y in range(0, height, self.patch_size):\n","            for x in range(0, width, self.patch_size):\n","                # Extract the patches of the batch\n","                patches_pr = y_pr[..., y:y + self.patch_size, x:x + self.patch_size]\n","                patches_gt = y_gt[..., y:y + self.patch_size, x:x + self.patch_size]\n","\n","                # Iterate through each patch of the prediction\n","                for i, patch_pr in enumerate(patches_pr):\n","                    # Calculate the average of the patch\n","                    patch_avg_pr = torch.mean(patch_pr)\n","                    # Patch threshold\n","                    if patch_avg_pr > self.patch_thr:\n","                        y_pr_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 1\n","                    else:\n","                        y_pr_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 0\n","\n","                # Iterate through each patch of the groundtruth mask\n","                for i, patch_gt in enumerate(patches_gt):\n","                    # Calculate the average of the patch\n","                    patch_avg_gt = torch.mean(patch_gt)\n","                    # Patch threshold\n","                    if patch_avg_gt > self.patch_thr:\n","                        y_gt_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 1\n","                    else:\n","                        y_gt_patch_tensor[i][0][y//self.patch_size][x//self.patch_size] = 0\n","\n","        tp, fp, fn, tn = smp.metrics.get_stats(y_pr_patch_tensor.to(torch.int), y_gt_patch_tensor.to(torch.int), mode='binary', threshold=self.threshold)\n","        f1_score_patch = smp.metrics.f1_score(tp=tp, fp=fp, fn=fn, tn=tn, reduction=\"micro\") #reduction=\"micro\" or \"micro-imagewise\"\n","\n","        return f1_score_patch"],"metadata":{"id":"SWipzfzoRDJ4","executionInfo":{"status":"ok","timestamp":1702541809437,"user_tz":-60,"elapsed":4,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ff0LsIB4QLCk"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6DbSV8Ar3STE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702510189897,"user_tz":-60,"elapsed":7,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"3566182c-3249-45f4-8608-0bea9f6f4339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: Tversky_Loss\n","Metric: custom__fscore\n"]}],"source":["## Choose different losses\n","if loss_type == \"dice\":\n","  loss_fn = smp.losses.dice.DiceLoss(mode ='binary')\n","  loss_fn.__name__ = 'Dice_loss'\n","  loss_name = 'Dice_loss'\n","elif loss_type == \"tversky\":\n","  loss_fn = smp.losses.tversky.TverskyLoss(mode ='binary', alpha = 0.7, beta = 0.3, gamma = 0.75)\n","  loss_fn.__name__ = 'Tversky_Loss'\n","  loss_name = 'Tversky_Loss'\n","\n","## Choose different metrics\n","if metric_type == \"custom\":\n","  metrics = [\n","        F1score_patch(), ]\n","  metric_name = \"custom__fscore\"\n","elif metric_type == \"fscore\":\n","  metrics = [\n","        smp_utils.metrics.Fscore(), ]\n","  metric_name = \"fscore\"\n","\n","print(\"Loss:\", loss_name)\n","print(\"Metric:\", metric_name)\n","metric_name_val = \"f1score_patch\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQ5zRnZM5w3v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702510192167,"user_tz":-60,"elapsed":1247,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"78d14ed9-1d07-4346-de58-45d2877cde97"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n","100%|██████████| 83.3M/83.3M [00:00<00:00, 310MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Unet\n"]}],"source":["models = [[smp.create_model(model_name, encoder_name=PARAMS[\"ENCODER\"], encoder_weights = PARAMS[\"ENCODER_WEIGHTS\"], in_channels=3, classes=1),model_name] for model_name in PARAMS[\"MODELS\"]]\n","for model,model_name in models:\n","  print(model_name)\n","  optimizer = torch.optim.Adam([\n","    dict(params=model.parameters(), lr=lr),\n","])\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, mode='min')\n","\n","  train_epoch = smp.utils.train.TrainEpoch(\n","      model,\n","      loss=loss_fn,\n","      metrics=metrics,\n","      optimizer=optimizer,\n","      device=\"cuda\",\n","      verbose=True,\n","  )\n","\n","  valid_epoch = smp.utils.train.ValidEpoch(\n","      model,\n","      loss=loss_fn,\n","      metrics=metrics,\n","      device=\"cuda\",\n","      verbose=True,\n","  )\n","\n","max_score = 0\n","train_loss_array = []\n","validation_loss_array = []\n","validation_fscore_array = []\n","\n","import torch\n","import gc\n","\n","def free_memory():\n","    # Clear GPU cache\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    # Clear system memory\n","    gc.collect()\n"]},{"cell_type":"code","source":["def model_training(alpha = 0.5, beta = 0.5, gamma = 1, lr = 1e-4):\n","  ## Loss and metric\n","  loss_fn = smp.losses.tversky.TverskyLoss(mode ='binary', alpha = alpha, beta = beta, gamma = gamma)\n","  loss_fn.__name__ = 'Tversky_Loss'\n","  loss_name = 'Tversky_Loss'\n","  metrics = [\n","        F1score_patch(), ]\n","  metric_name = \"custom__fscore\"\n","\n","  # train model for NB_EPOCHS\n","  for model,model_name in models:\n","    print(model_name)\n","    optimizer = torch.optim.Adam([\n","      dict(params=model.parameters(), lr=lr),])\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, mode='min')\n","    train_epoch = smp.utils.train.TrainEpoch(\n","        model,\n","        loss=loss_fn,\n","        metrics=metrics,\n","        optimizer=optimizer,\n","        device=\"cuda\",\n","        verbose=True,\n","    )\n","\n","    valid_epoch = smp.utils.train.ValidEpoch(\n","        model,\n","        loss=loss_fn,\n","        metrics=[smp_utils.metrics.Fscore(), F1score_patch(activation='sigmoid')], #metrics\n","        device=\"cuda\",\n","        verbose=True,\n","    )\n","\n","\n","    max_score = 0\n","    train_loss_array = []\n","    validation_loss_array = []\n","    validation_fscore_array = []\n","\n","\n","    try:\n","      for i in range(0, PARAMS[\"NB_EPOCHS\"]):\n","\n","          print('\\nEpoch: {}'.format(i))\n","          train_logs = train_epoch.run(train_loader)\n","          valid_logs = valid_epoch.run(valid_loader)\n","\n","          train_loss_array.append(train_logs[loss_name])\n","          validation_loss_array.append(valid_logs[loss_name])\n","          validation_fscore_array.append(valid_logs[metric_name_val])\n","          print(valid_logs)\n","          # do something (save model, change lr, etc.)\n","          if max_score < valid_logs[metric_name_val]:\n","              max_score = valid_logs[metric_name_val]\n","              torch.save(model, model_weights_folder + 'best_model_{}.pth'.format(model_name))\n","              print('Model saved!')\n","\n","          # Update the learning rate scheduler based on the validation loss\n","          scheduler.step(valid_logs[loss_name])\n","\n","          # Print the current learning rate\n","          current_lr = optimizer.param_groups[0]['lr']\n","          print(f'Current learning rate: {current_lr}')\n","\n","      epochs = range(0,len(train_loss_array))\n","      save_results(PARAMS,train_loss_array,validation_loss_array,validation_fscore_array)\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","    finally:\n","        # Free up memory\n","        free_memory()\n","\n","        # Optionally, delete large objects if they are no longer needed\n","        del model\n","        del optimizer\n","        del train_epoch\n","        del valid_epoch\n","\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(epochs, train_loss_array,\"o\", label='Training Loss')\n","        plt.plot(epochs, validation_loss_array,  label='Validation Loss')\n","        plt.plot(epochs, validation_fscore_array, \"o\" ,  label='Validation fscore')\n","        plt.title('Training and Validation Loss for {}'.format(model_name))\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","\n","        # Free up memory\n","        free_memory()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"zQBU-A3HVEze","executionInfo":{"status":"ok","timestamp":1702507235509,"user_tz":-60,"elapsed":19012,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"}},"outputId":"e94aa1b7-4b9e-4490-dabd-00fbb6fe45d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unet\n","\n","Epoch: 0\n","train: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it, Tversky_Loss - 0.3399, f1score_patch - 0.5469]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.41it/s, Tversky_Loss - 0.3436, fscore - 0.4159, f1score_patch - 0.8874]\n","{'Tversky_Loss': 0.3435864672064781, 'fscore': 0.4158823296427727, 'f1score_patch': 0.8874348312616348}\n","Model saved!\n","test\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":905},"executionInfo":{"elapsed":84293,"status":"error","timestamp":1702506979174,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"MkeHYzKRQOX-","outputId":"3cea9861-a783-46b4-b292-cf17a2e54d97"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 0\n","train: 100%|██████████| 10/10 [01:05<00:00,  6.54s/it, Tversky_Loss - 0.4984, f1score_patch - 0.0006944]\n","valid: 100%|██████████| 20/20 [00:18<00:00,  1.10it/s, Tversky_Loss - 0.5301, f1score_patch - 0.0]\n","An error occurred: 'custom__fscore'\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-e3d7cd6243b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_fscore_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation F-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training and Validation Loss for {model_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (0,)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["try:\n","    for i in range(PARAMS[\"NB_EPOCHS\"]):\n","        print('\\nEpoch: {}'.format(i))\n","        train_logs = train_epoch.run(train_loader)\n","        valid_logs = valid_epoch.run(valid_loader)\n","        train_loss_array.append(train_logs[loss_name])\n","\n","        validation_loss_array.append(valid_logs[loss_name])\n","        validation_fscore_array.append(valid_logs[metric_name])\n","        print(valid_logs)\n","        # do something (save model, change lr, etc.)\n","        if max_score < valid_logs[metric_name]:\n","            max_score = valid_logs[metric_name]\n","            torch.save(model, model_weights_folder + RUN_NAME +'{}.pth'.format(model_name))\n","            print('Model saved!')\n","\n","        # Update the learning rate scheduler based on the validation loss\n","        scheduler.step(valid_logs[loss_name])\n","\n","        # Print the current learning rate\n","        current_lr = optimizer.param_groups[0]['lr']\n","        print(f'Current learning rate: {current_lr}')\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","finally:\n","    # Free up memory\n","    free_memory()\n","\n","    # Optionally, delete large objects if they are no longer needed\n","    del model\n","    del optimizer\n","    del train_epoch\n","    del valid_epoch\n","    # del train_logs\n","    # del valid_logs\n","\n","    # Your existing code for plotting results\n","    epochs = range(0, len(train_loss_array))\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(epochs, train_loss_array, \"o\", label='Training Loss')\n","    plt.plot(epochs, validation_loss_array, label='Validation Loss')\n","    plt.plot(epochs, validation_fscore_array, \"o\", label='Validation F-score')\n","    plt.title(f'Training and Validation Loss for {model_name}')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Call free_memory() again to ensure all temporary objects are cleared\n","    free_memory()\n"]},{"cell_type":"markdown","source":["## Bayesian optimization"],"metadata":{"id":"Eu87vBiUSUAu"}},{"cell_type":"code","source":["def free_memory():\n","    # Clear GPU cache\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    # Clear system memory\n","    gc.collect()"],"metadata":{"id":"vPGSzPavXRr2","executionInfo":{"status":"ok","timestamp":1702541811660,"user_tz":-60,"elapsed":291,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import torch\n","import segmentation_models_pytorch as smp\n","import matplotlib.pyplot as plt\n","import gc  # Importing garbage collection module\n","\n","\n","# Function to initialize a new model\n","def initialize_model(model_name, encoder_name, encoder_weights, in_channels, classes):\n","    model = smp.create_model(model_name, encoder_name=encoder_name, encoder_weights=encoder_weights, in_channels=in_channels, classes=classes)\n","    return model\n","\n","def model_training(alpha=0.5, beta=0.5, gamma=1, lr=1e-4):\n","    best_validation_scores = []\n","\n","    ## Loss and metric\n","    loss_fn = smp.losses.tversky.TverskyLoss(mode ='binary', alpha = alpha, beta = beta, gamma = gamma)\n","    loss_fn.__name__ = 'Tversky_Loss'\n","    loss_name = 'Tversky_Loss'\n","    metrics = [\n","          F1score_patch(), ]\n","    metric_name = \"f1score_patch\"\n","\n","    # Loop through the models\n","    for _, model_name in models:  # Replace with your model names list\n","        # Reinitialize the model\n","        model = initialize_model(model_name, PARAMS[\"ENCODER\"], PARAMS[\"ENCODER_WEIGHTS\"], 3, 1)  # Adjust parameters as necessary\n","\n","        optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=lr)])\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, mode='min')\n","\n","        # # Loss and metric\n","        # loss_fn = smp.losses.tversky.TverskyLoss(mode='binary', alpha=alpha, beta=beta, gamma=gamma)\n","        # loss_fn.__name__ = 'Tversky_Loss'\n","        # loss_name = 'Tversky_Loss'\n","        # metric_name_val = \"f1score_patch\"\n","\n","        # Training and Validation setup\n","        train_epoch = smp.utils.train.TrainEpoch(\n","            model,\n","            loss=loss_fn,\n","            metrics=metrics,  # Define metrics\n","            optimizer=optimizer,\n","            device=\"cuda\",\n","            verbose=True)\n","\n","        valid_epoch = smp.utils.train.ValidEpoch(\n","            model,\n","            loss=loss_fn,\n","            metrics=[smp_utils.metrics.Fscore(), F1score_patch(activation='sigmoid')],  # Define metrics\n","            device=\"cuda\",\n","            verbose=True)\n","\n","        max_score = 0\n","        train_loss_array = []\n","        validation_loss_array = []\n","        validation_fscore_array = []\n","\n","        try:\n","            for i in range(PARAMS[\"NB_EPOCHS\"]):\n","                train_logs = train_epoch.run(train_loader)\n","                valid_logs = valid_epoch.run(valid_loader)\n","\n","                train_loss_array.append(train_logs[loss_name])\n","                validation_loss_array.append(valid_logs[loss_name])\n","                validation_fscore_array.append(valid_logs[metric_name_val])\n","\n","                if max_score < valid_logs[metric_name_val]:\n","                    max_score = valid_logs[metric_name_val]\n","                    torch.save(model, model_weights_folder + 'best_model_{}.pth'.format(model_name))\n","\n","                scheduler.step(valid_logs[loss_name])\n","\n","            save_results(PARAMS, train_loss_array, validation_loss_array, validation_fscore_array)\n","            best_validation_scores.append(max(validation_fscore_array))\n","\n","        except Exception as e:\n","            print(f\"An error occurred: {e}\")\n","\n","        finally:\n","            # Free up memory\n","            del model\n","            del optimizer\n","            torch.cuda.empty_cache()\n","\n","    # Optionally, include code for plotting results here\n","\n","    return max(best_validation_scores)\n","\n","# Define or import other necessary functions and variables like PARAMS, metrics, train_loader, valid_loader, save_results, etc.\n"],"metadata":{"id":"0ts6ccCNWkem","executionInfo":{"status":"ok","timestamp":1702541811962,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["import torch\n","import segmentation_models_pytorch as smp\n","import matplotlib.pyplot as plt\n","import gc  # Importing garbage collection module\n","\n","# Function to initialize a new model\n","def initialize_model(model_name, encoder_name, encoder_weights, in_channels, classes):\n","    model = smp.create_model(model_name, encoder_name=encoder_name, encoder_weights=encoder_weights, in_channels=in_channels, classes=classes)\n","    return model\n","\n","def model_training(alpha=0.5, beta=0.5, gamma=1, lr=1e-4):\n","    best_validation_scores = []\n","\n","    for _, model_name in models:  # Ensure 'models' is correctly defined\n","        # Reinitialize the model\n","        model = initialize_model(model_name, PARAMS[\"ENCODER\"], PARAMS[\"ENCODER_WEIGHTS\"], 3, 1)\n","\n","        optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=lr)])\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, mode='min')\n","\n","        # Define loss function and metrics\n","        loss_fn = smp.losses.tversky.TverskyLoss(mode='binary', alpha=alpha, beta=beta, gamma=gamma)\n","        loss_fn.__name__ = 'Tversky_Loss'\n","        loss_name = 'Tversky_Loss'\n","        metrics = [F1score_patch(), ]\n","        metric_name_val = \"f1score_patch\"\n","\n","        # Training and Validation setup\n","        train_epoch = smp.utils.train.TrainEpoch(model, loss=loss_fn, metrics=metrics, optimizer=optimizer, device=\"cuda\", verbose=True)\n","        valid_epoch = smp.utils.train.ValidEpoch(model, loss=loss_fn, metrics=[smp_utils.metrics.Fscore(), F1score_patch(activation='sigmoid')], device=\"cuda\", verbose=True)\n","\n","        max_score = 0\n","        train_loss_array = []\n","        validation_loss_array = []\n","        validation_fscore_array = []\n","\n","        try:\n","            for i in range(PARAMS[\"NB_EPOCHS\"]):\n","                train_logs = train_epoch.run(train_loader)\n","                valid_logs = valid_epoch.run(valid_loader)\n","\n","                train_loss_array.append(train_logs[loss_name])\n","                validation_loss_array.append(valid_logs[loss_name])\n","                validation_fscore_array.append(valid_logs[metric_name_val])\n","\n","                if max_score < valid_logs[metric_name_val]:\n","                    max_score = valid_logs[metric_name_val]\n","                    torch.save(model, model_weights_folder + 'best_model_{}.pth'.format(model_name))\n","\n","                scheduler.step(valid_logs[loss_name])\n","\n","            save_results(PARAMS, train_loss_array, validation_loss_array, validation_fscore_array)\n","            best_validation_scores.append(max(validation_fscore_array))\n","\n","        except Exception as e:\n","            print(f\"An error occurred: {e}\")\n","\n","        finally:\n","            # Explicitly free up memory\n","            del model\n","            del optimizer\n","            torch.cuda.empty_cache()\n","            gc.collect()  # Explicitly calling garbage collection\n","\n","    return max(best_validation_scores)\n","\n","# Define or import other necessary functions and variables like PARAMS, metrics, train_loader, valid_loader, save_results, etc.\n"],"metadata":{"id":"_82rRQzCa-pq","executionInfo":{"status":"ok","timestamp":1702542177271,"user_tz":-60,"elapsed":318,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from bayes_opt import BayesianOptimization\n","import torch\n","# models = [[smp.create_model(model_name, encoder_name=PARAMS[\"ENCODER\"], encoder_weights = PARAMS[\"ENCODER_WEIGHTS\"], in_channels=3, classes=1),model_name] for model_name in PARAMS[\"MODELS\"]]\n","\n","def bayesian_optimization(preloaded_points):\n","    # Define the bounds for each parameter\n","    pbounds = {\n","        'alpha': (0.3, 0.7),  # Range for alpha\n","        'beta': (0.3, 0.7),   # Range for beta\n","        'gamma': (0.5, 2),    # Range for gamma\n","        'lr': (1e-5, 1e-3)    # Range for learning rate\n","    }\n","\n","    optimizer = BayesianOptimization(\n","        f=model_training,\n","        pbounds=pbounds,\n","        random_state=1,\n","    )\n","\n","    # Register preloaded points\n","    for point in preloaded_points:\n","        optimizer.register(params=point['params'], target=point['target'])\n","\n","    # Perform optimization\n","    optimizer.maximize(\n","        init_points=2,  # Number of random initial points\n","        n_iter=10,      # Number of iterations\n","    )\n","\n","    # Print the best parameters found\n","    print(\"Best Parameters: \", optimizer.max['params'])\n","\n","# Example usage\n","# preloaded_points = [\n","#     {\"params\": {\"alpha\": 0.4668, \"beta\": 0.5881, \"gamma\": 0.5002 , \"lr\":  0.0003093}, \"target\": 0.9366 },\n","#     {\"params\": {\"alpha\": 0.3587, \"beta\": 0.3369 , \"gamma\": 0.7794  , \"lr\":  0.0003521}, \"target\": 0.9313 },\n","#     {\"params\": {\"alpha\": 0.3031, \"beta\": 0.3647 , \"gamma\": 1.564  , \"lr\":  0.0007671}, \"target\": 0.9234  },\n","#     {\"params\": {\"alpha\": 0.7  , \"beta\": 0.7  , \"gamma\": 0.7313   , \"lr\":  0.001  }, \"target\": 0.9442  },\n","#     {\"params\": {\"alpha\": 0.677, \"beta\": 0.6671  , \"gamma\": 0.7218 , \"lr\":  0.0007869}, \"target\": 0.9465 },\n","#     # ... add more points if available\n","# ]\n","# Run Bayesian Optimization with preloaded points\n","# bayesian_optimization(preloaded_points)\n"],"metadata":{"id":"pCPQtlF-V6bF","executionInfo":{"status":"ok","timestamp":1702542183648,"user_tz":-60,"elapsed":2,"user":{"displayName":"Victor","userId":"16057659027853074662"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["preloaded_points= []\n","bayesian_optimization(preloaded_points)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"id":"H0DJa8JgZeyC","executionInfo":{"status":"error","timestamp":1702542259998,"user_tz":-60,"elapsed":72418,"user":{"displayName":"Victor","userId":"16057659027853074662"}},"outputId":"b077f68b-6fb1-46a9-f899-d0a18fb088db"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   |   alpha   |   beta    |   gamma   |    lr     |\n","-------------------------------------------------------------------------\n","train: 100%|██████████| 10/10 [00:11<00:00,  1.12s/it, Tversky_Loss - 0.587, f1score_patch - 0.8183]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.85it/s, Tversky_Loss - 0.6095, fscore - 0.5107, f1score_patch - 0.8667]\n","test\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.8667   \u001b[0m | \u001b[0m0.4668   \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.5002   \u001b[0m | \u001b[0m0.0003093\u001b[0m |\n","train: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it, Tversky_Loss - 0.3557, f1score_patch - 0.6207]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.91it/s, Tversky_Loss - 0.5125, fscore - 0.2324, f1score_patch - 0.5056]\n","test\n","| \u001b[0m2        \u001b[0m | \u001b[0m0.5056   \u001b[0m | \u001b[0m0.3587   \u001b[0m | \u001b[0m0.3369   \u001b[0m | \u001b[0m0.7794   \u001b[0m | \u001b[0m0.0003521\u001b[0m |\n","train: 100%|██████████| 10/10 [00:11<00:00,  1.19s/it, Tversky_Loss - 0.1091, f1score_patch - 0.7403]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.56it/s, Tversky_Loss - 0.1591, fscore - 0.6732, f1score_patch - 0.7286]\n","test\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.7286   \u001b[0m | \u001b[0m0.3031   \u001b[0m | \u001b[0m0.3647   \u001b[0m | \u001b[0m1.564    \u001b[0m | \u001b[0m0.0007671\u001b[0m |\n","train: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it, Tversky_Loss - 0.1463, f1score_patch - 0.8823]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.20it/s, Tversky_Loss - 0.2055, fscore - 0.7294, f1score_patch - 0.842]\n","test\n","| \u001b[0m4        \u001b[0m | \u001b[0m0.842    \u001b[0m | \u001b[0m0.477    \u001b[0m | \u001b[0m0.4654   \u001b[0m | \u001b[0m1.322    \u001b[0m | \u001b[0m0.0007468\u001b[0m |\n","train:  50%|█████     | 5/10 [00:07<00:07,  1.45s/it, Tversky_Loss - 0.07523, f1score_patch - 0.8465]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-80a9c523d7e0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreloaded_points\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbayesian_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreloaded_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-677a6b6cff83>\u001b[0m in \u001b[0;36mbayesian_optimization\u001b[0;34m(preloaded_points)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Perform optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     optimizer.maximize(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Number of random initial points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-594c1caaf80d>\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(alpha, beta, gamma, lr)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NB_EPOCHS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mvalid_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/utils/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# update metrics logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmetric_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mmetric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0mmetrics_meters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mmetrics_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics_meters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-b8fb446b84bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pr, y_gt)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# Iterate through each patch of the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_pr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# Calculate the average of the patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mpatch_avg_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0;31m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# generator and don't eagerly perform all the indexes.  This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from bayes_opt import BayesianOptimization\n","import torch\n","\n","def bayesian_optimization():\n","    # Define the bounds for each parameter\n","    pbounds = {\n","        'alpha': (0.3, 0.7),  # Example range for alpha\n","        'beta': (0.3, 0.7),   # Example range for beta\n","        'gamma': (0.5, 2),    # Example range for gamma\n","        'lr': (1e-5, 1e-3)    # Example range for learning rate\n","    }\n","\n","    optimizer = BayesianOptimization(\n","        f=model_training,\n","        pbounds=pbounds,\n","        random_state=1,\n","    )\n","\n","    # Perform optimization\n","    optimizer.maximize(\n","        init_points=2,  # Number of random initial points\n","        n_iter=10,      # Number of iterations\n","    )\n","\n","    # Print the best parameters found\n","    print(\"Best Parameters: \", optimizer.max['params'])\n","\n","# Run Bayesian Optimization\n","bayesian_optimization()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nZKzjk6YIhe","outputId":"97d8f03b-5923-48c1-8443-dc15d932a9e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   |   alpha   |   beta    |   gamma   |    lr     |\n","-------------------------------------------------------------------------\n","train: 100%|██████████| 127/127 [08:20<00:00,  3.94s/it, Tversky_Loss - 0.4877, f1score_patch - 0.8084]\n","valid: 100%|██████████| 20/20 [00:24<00:00,  1.23s/it, Tversky_Loss - 0.3851, fscore - 0.899, f1score_patch - 0.9238]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.3216, f1score_patch - 0.9398]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.20it/s, Tversky_Loss - 0.378, fscore - 0.8552, f1score_patch - 0.886]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.2894, f1score_patch - 0.9421]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.41it/s, Tversky_Loss - 0.322, fscore - 0.8935, f1score_patch - 0.9191]\n","train: 100%|██████████| 127/127 [02:20<00:00,  1.11s/it, Tversky_Loss - 0.2739, f1score_patch - 0.9453]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.45it/s, Tversky_Loss - 0.2904, fscore - 0.9109, f1score_patch - 0.9328]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.2713, f1score_patch - 0.945]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.31it/s, Tversky_Loss - 0.3157, fscore - 0.8909, f1score_patch - 0.917]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.2707, f1score_patch - 0.9447]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.78it/s, Tversky_Loss - 0.5095, fscore - 0.7248, f1score_patch - 0.7622]\n","train: 100%|██████████| 127/127 [02:27<00:00,  1.16s/it, Tversky_Loss - 0.263, f1score_patch - 0.9474]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.05it/s, Tversky_Loss - 0.3043, fscore - 0.8982, f1score_patch - 0.9223]\n","train: 100%|██████████| 127/127 [02:25<00:00,  1.15s/it, Tversky_Loss - 0.2626, f1score_patch - 0.947]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, Tversky_Loss - 0.2865, fscore - 0.9085, f1score_patch - 0.9311]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.13s/it, Tversky_Loss - 0.2561, f1score_patch - 0.9493]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.15it/s, Tversky_Loss - 0.2983, fscore - 0.9011, f1score_patch - 0.9245]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2533, f1score_patch - 0.95]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.30it/s, Tversky_Loss - 0.3048, fscore - 0.8955, f1score_patch - 0.9202]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.2449, f1score_patch - 0.9532]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.27it/s, Tversky_Loss - 0.3185, fscore - 0.8861, f1score_patch - 0.9145]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.2434, f1score_patch - 0.9529]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.11it/s, Tversky_Loss - 0.2979, fscore - 0.9004, f1score_patch - 0.9248]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2615, f1score_patch - 0.9462]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.93it/s, Tversky_Loss - 0.2731, fscore - 0.9168, f1score_patch - 0.9366]\n","train: 100%|██████████| 127/127 [02:25<00:00,  1.14s/it, Tversky_Loss - 0.2401, f1score_patch - 0.954]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.01it/s, Tversky_Loss - 0.2864, fscore - 0.9091, f1score_patch - 0.9287]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2387, f1score_patch - 0.9537]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.98it/s, Tversky_Loss - 0.3028, fscore - 0.8961, f1score_patch - 0.9207]\n","test\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.9366   \u001b[0m | \u001b[0m0.4668   \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.5002   \u001b[0m | \u001b[0m0.0003093\u001b[0m |\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.2155, f1score_patch - 0.846]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.26it/s, Tversky_Loss - 0.1784, fscore - 0.8956, f1score_patch - 0.9186]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.1321, f1score_patch - 0.9407]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.29it/s, Tversky_Loss - 0.1575, fscore - 0.8854, f1score_patch - 0.9142]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.1122, f1score_patch - 0.9444]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.37it/s, Tversky_Loss - 0.1408, fscore - 0.8974, f1score_patch - 0.9203]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.1035, f1score_patch - 0.9464]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.24it/s, Tversky_Loss - 0.1429, fscore - 0.8915, f1score_patch - 0.9185]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.1053, f1score_patch - 0.9445]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.85it/s, Tversky_Loss - 0.1343, fscore - 0.8972, f1score_patch - 0.9223]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.101, f1score_patch - 0.9464]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.41it/s, Tversky_Loss - 0.1387, fscore - 0.893, f1score_patch - 0.9189]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.09816, f1score_patch - 0.9486]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.58it/s, Tversky_Loss - 0.1204, fscore - 0.9092, f1score_patch - 0.9313]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.09262, f1score_patch - 0.9515]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.07it/s, Tversky_Loss - 0.1279, fscore - 0.9027, f1score_patch - 0.9268]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.09302, f1score_patch - 0.9508]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.09it/s, Tversky_Loss - 0.1443, fscore - 0.8865, f1score_patch - 0.915]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.09045, f1score_patch - 0.9522]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.35it/s, Tversky_Loss - 0.1413, fscore - 0.889, f1score_patch - 0.9165]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.08585, f1score_patch - 0.9547]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.72it/s, Tversky_Loss - 0.1431, fscore - 0.8873, f1score_patch - 0.9156]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.08362, f1score_patch - 0.9557]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.10it/s, Tversky_Loss - 0.1337, fscore - 0.8963, f1score_patch - 0.9219]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.08106, f1score_patch - 0.9571]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.35it/s, Tversky_Loss - 0.1439, fscore - 0.8863, f1score_patch - 0.9153]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.07897, f1score_patch - 0.9586]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.42it/s, Tversky_Loss - 0.1303, fscore - 0.8993, f1score_patch - 0.9226]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.07709, f1score_patch - 0.9595]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.35it/s, Tversky_Loss - 0.124, fscore - 0.9051, f1score_patch - 0.9274]\n","test\n","| \u001b[0m2        \u001b[0m | \u001b[0m0.9313   \u001b[0m | \u001b[0m0.3587   \u001b[0m | \u001b[0m0.3369   \u001b[0m | \u001b[0m0.7794   \u001b[0m | \u001b[0m0.0003521\u001b[0m |\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.13s/it, Tversky_Loss - 0.04015, f1score_patch - 0.8924]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.30it/s, Tversky_Loss - 0.02302, fscore - 0.897, f1score_patch - 0.9217]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.01456, f1score_patch - 0.9378]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.09it/s, Tversky_Loss - 0.02044, fscore - 0.8869, f1score_patch - 0.9149]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.01298, f1score_patch - 0.9384]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.34it/s, Tversky_Loss - 0.02119, fscore - 0.884, f1score_patch - 0.9117]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.01161, f1score_patch - 0.9413]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.78it/s, Tversky_Loss - 0.01731, fscore - 0.897, f1score_patch - 0.9234]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.01173, f1score_patch - 0.9401]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.05it/s, Tversky_Loss - 0.01914, fscore - 0.8887, f1score_patch - 0.9159]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.01051, f1score_patch - 0.9443]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.94it/s, Tversky_Loss - 0.01982, fscore - 0.8841, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.01152, f1score_patch - 0.94]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.32it/s, Tversky_Loss - 0.01972, fscore - 0.8833, f1score_patch - 0.9132]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.01404, f1score_patch - 0.9301]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.42it/s, Tversky_Loss - 0.01949, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.01225, f1score_patch - 0.9367]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.28it/s, Tversky_Loss - 0.01955, fscore - 0.8843, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.01124, f1score_patch - 0.9407]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.27it/s, Tversky_Loss - 0.01948, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.01211, f1score_patch - 0.9373]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.20it/s, Tversky_Loss - 0.01813, fscore - 0.8897, f1score_patch - 0.9167]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.01035, f1score_patch - 0.9438]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.15it/s, Tversky_Loss - 0.01803, fscore - 0.8905, f1score_patch - 0.9179]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.13s/it, Tversky_Loss - 0.01018, f1score_patch - 0.9443]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.36it/s, Tversky_Loss - 0.01939, fscore - 0.8842, f1score_patch - 0.9138]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.01007, f1score_patch - 0.9454]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.33it/s, Tversky_Loss - 0.01916, fscore - 0.8852, f1score_patch - 0.9144]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.009544, f1score_patch - 0.9476]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.77it/s, Tversky_Loss - 0.01847, fscore - 0.888, f1score_patch - 0.9166]\n","test\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.9234   \u001b[0m | \u001b[0m0.3031   \u001b[0m | \u001b[0m0.3647   \u001b[0m | \u001b[0m1.564    \u001b[0m | \u001b[0m0.0007671\u001b[0m |\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.2864, f1score_patch - 0.898]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.37it/s, Tversky_Loss - 0.2678, fscore - 0.8794, f1score_patch - 0.9046]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2222, f1score_patch - 0.9328]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, Tversky_Loss - 0.2262, fscore - 0.9015, f1score_patch - 0.9235]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2048, f1score_patch - 0.938]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.32it/s, Tversky_Loss - 0.2541, fscore - 0.881, f1score_patch - 0.9072]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2104, f1score_patch - 0.9358]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.59it/s, Tversky_Loss - 0.2181, fscore - 0.905, f1score_patch - 0.926]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.1958, f1score_patch - 0.9412]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.20it/s, Tversky_Loss - 0.2169, fscore - 0.9047, f1score_patch - 0.9288]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.195, f1score_patch - 0.9418]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.32it/s, Tversky_Loss - 0.2083, fscore - 0.9104, f1score_patch - 0.9293]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.191, f1score_patch - 0.9431]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.34it/s, Tversky_Loss - 0.2351, fscore - 0.8938, f1score_patch - 0.9146]\n","train: 100%|██████████| 127/127 [02:25<00:00,  1.15s/it, Tversky_Loss - 0.1869, f1score_patch - 0.9442]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.17it/s, Tversky_Loss - 0.2163, fscore - 0.9055, f1score_patch - 0.9255]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.13s/it, Tversky_Loss - 0.1863, f1score_patch - 0.9444]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.04it/s, Tversky_Loss - 0.2068, fscore - 0.9097, f1score_patch - 0.9316]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.185, f1score_patch - 0.9446]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.24it/s, Tversky_Loss - 0.2156, fscore - 0.9051, f1score_patch - 0.9279]\n","train: 100%|██████████| 127/127 [02:25<00:00,  1.15s/it, Tversky_Loss - 0.1834, f1score_patch - 0.9454]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, Tversky_Loss - 0.212, fscore - 0.9068, f1score_patch - 0.9316]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.13s/it, Tversky_Loss - 0.1786, f1score_patch - 0.9472]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.62it/s, Tversky_Loss - 0.211, fscore - 0.9076, f1score_patch - 0.9294]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.177, f1score_patch - 0.9477]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.81it/s, Tversky_Loss - 0.177, fscore - 0.9267, f1score_patch - 0.9442]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.1735, f1score_patch - 0.9493]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.30it/s, Tversky_Loss - 0.243, fscore - 0.8875, f1score_patch - 0.9155]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.1786, f1score_patch - 0.9473]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.31it/s, Tversky_Loss - 0.1896, fscore - 0.9195, f1score_patch - 0.9378]\n","test\n","| \u001b[95m4        \u001b[0m | \u001b[95m0.9442   \u001b[0m | \u001b[95m0.7      \u001b[0m | \u001b[95m0.7      \u001b[0m | \u001b[95m0.7313   \u001b[0m | \u001b[95m0.001    \u001b[0m |\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2735, f1score_patch - 0.9206]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.20it/s, Tversky_Loss - 0.2442, fscore - 0.8963, f1score_patch - 0.9221]\n","train: 100%|██████████| 127/127 [02:24<00:00,  1.14s/it, Tversky_Loss - 0.2141, f1score_patch - 0.9352]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.30it/s, Tversky_Loss - 0.2481, fscore - 0.8885, f1score_patch - 0.9149]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.203, f1score_patch - 0.9388]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.29it/s, Tversky_Loss - 0.2364, fscore - 0.8934, f1score_patch - 0.9187]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.2021, f1score_patch - 0.9388]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.32it/s, Tversky_Loss - 0.2216, fscore - 0.9031, f1score_patch - 0.925]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.1996, f1score_patch - 0.9394]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.31it/s, Tversky_Loss - 0.2113, fscore - 0.9071, f1score_patch - 0.9306]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.1979, f1score_patch - 0.9401]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.79it/s, Tversky_Loss - 0.2098, fscore - 0.9077, f1score_patch - 0.9284]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.1865, f1score_patch - 0.9443]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.03it/s, Tversky_Loss - 0.2, fscore - 0.9135, f1score_patch - 0.936]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.1822, f1score_patch - 0.9466]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.27it/s, Tversky_Loss - 0.1692, fscore - 0.9315, f1score_patch - 0.9465]\n","train: 100%|██████████| 127/127 [02:23<00:00,  1.13s/it, Tversky_Loss - 0.1851, f1score_patch - 0.9451]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.34it/s, Tversky_Loss - 0.1922, fscore - 0.918, f1score_patch - 0.9368]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.1788, f1score_patch - 0.9477]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.45it/s, Tversky_Loss - 0.229, fscore - 0.8971, f1score_patch - 0.9223]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.1821, f1score_patch - 0.9465]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.43it/s, Tversky_Loss - 0.2143, fscore - 0.9046, f1score_patch - 0.9275]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.13s/it, Tversky_Loss - 0.1773, f1score_patch - 0.9482]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.34it/s, Tversky_Loss - 0.2203, fscore - 0.9018, f1score_patch - 0.9252]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.1757, f1score_patch - 0.9488]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  6.79it/s, Tversky_Loss - 0.1879, fscore - 0.9203, f1score_patch - 0.9374]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.1716, f1score_patch - 0.9503]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.41it/s, Tversky_Loss - 0.206, fscore - 0.9097, f1score_patch - 0.9318]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.1704, f1score_patch - 0.95]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s, Tversky_Loss - 0.1714, fscore - 0.9292, f1score_patch - 0.9445]\n","test\n","| \u001b[95m5        \u001b[0m | \u001b[95m0.9465   \u001b[0m | \u001b[95m0.677    \u001b[0m | \u001b[95m0.6671   \u001b[0m | \u001b[95m0.7218   \u001b[0m | \u001b[95m0.0007869\u001b[0m |\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.02571, f1score_patch - 0.9164]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.77it/s, Tversky_Loss - 0.01306, fscore - 0.8941, f1score_patch - 0.9195]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.007079, f1score_patch - 0.9391]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.83it/s, Tversky_Loss - 0.01377, fscore - 0.8743, f1score_patch - 0.9052]\n","train: 100%|██████████| 127/127 [02:20<00:00,  1.11s/it, Tversky_Loss - 0.006482, f1score_patch - 0.9321]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, Tversky_Loss - 0.009674, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.005953, f1score_patch - 0.932]\n","valid: 100%|██████████| 20/20 [00:04<00:00,  4.35it/s, Tversky_Loss - 0.009035, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.005641, f1score_patch - 0.9324]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  5.58it/s, Tversky_Loss - 0.008861, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.004983, f1score_patch - 0.937]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.05it/s, Tversky_Loss - 0.008597, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.00502, f1score_patch - 0.9357]\n","valid: 100%|██████████| 20/20 [00:03<00:00,  6.57it/s, Tversky_Loss - 0.008566, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.005988, f1score_patch - 0.9272]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.18it/s, Tversky_Loss - 0.008812, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.12s/it, Tversky_Loss - 0.004624, f1score_patch - 0.9394]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.31it/s, Tversky_Loss - 0.008433, fscore - 0.8842, f1score_patch - 0.9137]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.005066, f1score_patch - 0.9341]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.37it/s, Tversky_Loss - 0.008899, fscore - 0.8848, f1score_patch - 0.9156]\n","train: 100%|██████████| 127/127 [02:21<00:00,  1.11s/it, Tversky_Loss - 0.005483, f1score_patch - 0.93]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.47it/s, Tversky_Loss - 0.008473, fscore - 0.884, f1score_patch - 0.9134]\n","train: 100%|██████████| 127/127 [02:22<00:00,  1.12s/it, Tversky_Loss - 0.005243, f1score_patch - 0.9319]\n","valid: 100%|██████████| 20/20 [00:02<00:00,  7.40it/s, Tversky_Loss - 0.02549, fscore - 0.834, f1score_patch - 0.8775]\n","train:   1%|          | 1/127 [00:01<02:18,  1.10s/it, Tversky_Loss - 0.005977, f1score_patch - 0.9237]"]}]},{"cell_type":"markdown","metadata":{"id":"6Ew5bqktDzyf"},"source":["# II) Visualization & Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":294,"status":"error","timestamp":1702508431275,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"aCmTrHfKtTvX","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"7d23c98a-266e-41e5-e62f-e717f8252e15"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-1cd73bdf8208>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mforeground_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m  \u001b[0;31m# Threshold for determining foreground vs background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './submissions/models/vic7_bo_vaugUnet.pth'"]}],"source":["MODEL_NAME = \"Unet\"\n","MODEL_PATH = model_weights_folder + f'{RUN_NAME + MODEL_NAME}.pth'\n","# MODEL_PATH = model_weights_folder + 'test_best_model_Unet.pth'\n","DEVICE ='cuda'\n","\n","test_model = torch.load(MODEL_PATH)\n","\n","foreground_threshold = 0.5  # Threshold for determining foreground vs background"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Em4YkdzwJ6e"},"outputs":[],"source":["test_dataset = Dataset(\n","    images_dir=\"./data/test_set_images/\",\n","    preprocessing= get_preprocessing(preprocessing_fn),\n","    classes=['road'])\n","\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n"]},{"cell_type":"markdown","metadata":{"id":"t0WuNZLfOcxk"},"source":["### Visualization"]},{"cell_type":"code","source":["# Ensure the model is on the correct device and in evaluation mode\n","test_model = test_model.to(DEVICE)\n","test_model.eval()\n","activate_threshold = True\n","img_nbr = 4\n","i = 0\n","# Iterate over all batches in the test_loader\n","for batch in test_loader:\n","    i += 1\n","    with torch.no_grad():\n","        # Move input to the device where the model is\n","        input_tensors = batch[1].to(DEVICE)\n","        logits = test_model(input_tensors)\n","        pr_gts = logits.sigmoid()\n","\n","        # Since there are no ground truth masks, we only visualize the images and predictions\n","        for img_fp, pr_gt in zip(batch[0], pr_gts):  # batch[0] should contain the file paths\n","            print(img_fp)\n","            img = cv2.imread(img_fp)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            # img = cv2.resize(img, (416, 416))\n","\n","            # Get the prediction as a numpy array\n","            pr_gt_cpu = pr_gt.cpu().numpy().squeeze()\n","            if activate_threshold:\n","              pr_gt_cpu[pr_gt_cpu >= foreground_threshold] = 1\n","              pr_gt_cpu[pr_gt_cpu < foreground_threshold] = 0\n","\n","            plt.figure(figsize=(10, 5))\n","\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(img)  # No need to transpose axes since img is read with cv2 and already in HWC format\n","            plt.title(\"Image\")\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(pr_gt_cpu, cmap='gray')  # Show the prediction\n","            plt.title(\"Prediction\")\n","            plt.axis(\"off\")\n","\n","            plt.show()\n","    if i == img_nbr:\n","      break\n"],"metadata":{"id":"WOb7x5YMaKIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rnY2IdMNOlJBIfUJueJZGIjePGQJRtGt"},"executionInfo":{"elapsed":48687,"status":"ok","timestamp":1702305672257,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"LK85TaeB9xvp","outputId":"2ed53c65-42e9-4e74-d1bb-664c8466ac6a"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Ensure the model is on the correct device and in evaluation mode\n","test_model = test_model.to(DEVICE)\n","test_model.eval()\n","activate_threshold = True\n","img_nbr = 50\n","i = 0\n","# Iterate over all batches in the test_loader\n","for batch in test_loader:\n","    i += 1\n","    with torch.no_grad():\n","        # Move input to the device where the model is\n","        input_tensors = batch[1].to(DEVICE)\n","        logits = test_model(input_tensors)\n","        pr_gts = logits.sigmoid()\n","\n","        # Since there are no ground truth masks, we only visualize the images and predictions\n","        for img_fp, pr_gt in zip(batch[0], pr_gts):  # batch[0] should contain the file paths\n","            print(img_fp)\n","            img = cv2.imread(img_fp)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            # img = cv2.resize(img, (416, 416))\n","\n","            # Get the prediction as a numpy array\n","            pr_gt_cpu = pr_gt.cpu().numpy().squeeze()\n","            if activate_threshold:\n","              pr_gt_cpu[pr_gt_cpu >= foreground_threshold] = 1\n","              pr_gt_cpu[pr_gt_cpu < foreground_threshold] = 0\n","\n","            plt.figure(figsize=(10, 5))\n","\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(img)  # No need to transpose axes since img is read with cv2 and already in HWC format\n","            plt.title(\"Image\")\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(pr_gt_cpu, cmap='gray')  # Show the prediction\n","            plt.title(\"Prediction\")\n","            plt.axis(\"off\")\n","\n","            plt.show()\n","    if i == img_nbr:\n","      break\n"]},{"cell_type":"markdown","metadata":{"id":"fGc58H45Oew-"},"source":["### .csv File"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3972,"status":"ok","timestamp":1702305697393,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"B0EFXffyS-yc","outputId":"81c93a44-1e40-4bf3-eb98-0882a58ce933"},"outputs":[{"output_type":"stream","name":"stdout","text":["./data/test_set_images/test_1/test_1.png\n","./data/test_set_images/test_2/test_2.png\n","./data/test_set_images/test_3/test_3.png\n","./data/test_set_images/test_4/test_4.png\n","./data/test_set_images/test_5/test_5.png\n","./data/test_set_images/test_6/test_6.png\n","./data/test_set_images/test_7/test_7.png\n","./data/test_set_images/test_8/test_8.png\n","./data/test_set_images/test_9/test_9.png\n","./data/test_set_images/test_10/test_10.png\n","./data/test_set_images/test_11/test_11.png\n","./data/test_set_images/test_12/test_12.png\n","./data/test_set_images/test_13/test_13.png\n","./data/test_set_images/test_14/test_14.png\n","./data/test_set_images/test_15/test_15.png\n","./data/test_set_images/test_16/test_16.png\n","./data/test_set_images/test_17/test_17.png\n","./data/test_set_images/test_18/test_18.png\n","./data/test_set_images/test_19/test_19.png\n","./data/test_set_images/test_20/test_20.png\n","./data/test_set_images/test_21/test_21.png\n","./data/test_set_images/test_22/test_22.png\n","./data/test_set_images/test_23/test_23.png\n","./data/test_set_images/test_24/test_24.png\n","./data/test_set_images/test_25/test_25.png\n","./data/test_set_images/test_26/test_26.png\n","./data/test_set_images/test_27/test_27.png\n","./data/test_set_images/test_28/test_28.png\n","./data/test_set_images/test_29/test_29.png\n","./data/test_set_images/test_30/test_30.png\n","./data/test_set_images/test_31/test_31.png\n","./data/test_set_images/test_32/test_32.png\n","./data/test_set_images/test_33/test_33.png\n","./data/test_set_images/test_34/test_34.png\n","./data/test_set_images/test_35/test_35.png\n","./data/test_set_images/test_36/test_36.png\n","./data/test_set_images/test_37/test_37.png\n","./data/test_set_images/test_38/test_38.png\n","./data/test_set_images/test_39/test_39.png\n","./data/test_set_images/test_40/test_40.png\n","./data/test_set_images/test_41/test_41.png\n","./data/test_set_images/test_42/test_42.png\n","./data/test_set_images/test_43/test_43.png\n","./data/test_set_images/test_44/test_44.png\n","./data/test_set_images/test_45/test_45.png\n","./data/test_set_images/test_46/test_46.png\n","./data/test_set_images/test_47/test_47.png\n","./data/test_set_images/test_48/test_48.png\n","./data/test_set_images/test_49/test_49.png\n","./data/test_set_images/test_50/test_50.png\n"]}],"source":["### with average of multiple predictions\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","test_model = test_model.to(DEVICE)\n","\n","# Parameters for saving images\n","output_folder = submission_folder + 'eval_imgs/'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Iterate over the DataLoader\n","for i, (path, image) in enumerate(test_loader):\n","    path = path[0]\n","    with torch.no_grad():\n","        test_model.eval()\n","        # Move input to the device\n","        input_tensor = image.to(DEVICE)\n","        n, c, h, w = input_tensor.size()\n","        sum = torch.zeros((n, 1, h, w), device='cuda')\n","        for i in range(4):\n","          img_rot = torch.rot90(input_tensor, i%4, [2, 3])\n","          prediction = test_model(img_rot)\n","          prediction = torch.rot90(prediction, 4-(i%4), [2, 3]) #rotation back\n","          sum += prediction\n","\n","        pred = sum / 4\n","        pred_np = pred.detach().cpu().numpy()[0, 0]\n","        pred_np = 1 / (1 + np.exp(-pred_np))\n","        pred_voting = (pred_np > 0.5).astype(float)*255\n","\n","        # Save the image\n","        image_num = path.split('/')[-1].split('_')[-1].split('.')[0]\n","        image_num = int(image_num)\n","        filename = \"test_eval_\" + '%.3d' % image_num + '.png'\n","\n","        cv2.imwrite(os.path.join(output_folder, filename), pred_voting)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fEJ3U7m14PBd"},"outputs":[],"source":["submission_filename = submission_folder + 'test_submission.csv'\n","image_filenames = []\n","for i in range(1, 51):\n","    # image_filename = 'training/groundtruth/satImage_' + '%.3d' % i + '.png'\n","    image_filename = submission_folder + 'eval_imgs/test_eval_' + '%.3d' % i + '.png'\n","    image_filenames.append(image_filename)\n","masks_to_submission(submission_filename, *image_filenames)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1702305698740,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"_OFYkYKz0PO7","outputId":"d9a44d4b-dca7-43cf-d2fb-0c3a46bcd4df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./submissions/submission_vic_aug6/test_submission.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}],"source":["submission_filename"]},{"cell_type":"markdown","metadata":{"id":"JX4EAaWwa0wd"},"source":["# Second DL network (cascade)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wq6PKDx39Y6"},"outputs":[],"source":["PARAMS = {\n","  'MODELS' : [\"Unet\"], # Available : \"Unet\",\"DeepLabV3\",\"FPN\", \"UnetPlusPlus\"\n","  'ENCODER' : 'resnet34',\n","  'ENCODER_WEIGHTS' : 'imagenet',\n","  'NB_EPOCHS' : 25,\n","  'ACTIVATION' : 'sigmoid', # could be None for logits or 'softmax2d' for multiclass segmentation,\n","  'DATA_AUGMENTATION' : True, #choose whether the data is augmented to 900 images or use original dataset of 100 images,\n","  'CLASSES' : ['road'],\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSOUSPenbGFj"},"outputs":[],"source":["# Default parameters for various parts\n","foreground_threshold = 0.5  # Threshold for determining foreground vs background\n","lr = 1e-4\n","\n","# Loss and metric type\n","loss_type = \"dice\" # Possible: [\"dice\", \"tversky\", \"custom\"]\n","metric_type = \"fscore\" # custom: [\"custom\", \"fscore\"]"]},{"cell_type":"markdown","metadata":{"id":"qSfPbR_-fWQP"},"source":["## Dataset class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VevxwbBXfV_w"},"outputs":[],"source":["class Dataset2(BaseDataset):\n","  CLASSES = ['road', 'unlabelled']\n","  def __init__(self, images_dir, masks_dir=None, classes=None, augmentation=None, preprocessing=None, plot = False):\n","      self.ids = os.listdir(images_dir)\n","      self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","      self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids] if masks_dir is not None else None\n","\n","      # convert str names to class values on masks\n","      if classes is not None:\n","          self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n","\n","      self.augmentation = augmentation\n","      self.preprocessing = preprocessing\n","      # self.preprocessing = None\n","      self.plot = plot\n","\n","  def __getitem__(self, i):\n","\n","      # read data\n","      image = cv2.imread(self.images_fps[i])\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      # image = cv2.resize(image, (416, 416))\n","      # initialize mask as None\n","      mask = None\n","\n","      if self.masks_fps == None:\n","        print(self.images_fps[i])\n","        if self.augmentation:\n","          sample = self.augmentation(image=image)\n","          image = sample['image']\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image)\n","            image = sample['image']\n","        return self.images_fps[i], image\n","\n","      else:\n","        mask = cv2.imread(self.masks_fps[i], 0)\n","        # mask = cv2.resize(mask, (416, 416))\n","        masks = [(mask == v) for v in self.class_values]\n","        mask = np.stack(masks, axis=-1).astype('float')\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","        if self.preprocessing:\n","              sample = self.preprocessing(image=image, mask=mask)\n","              image, mask = sample['image'], sample['mask']\n","        return image, mask\n","\n","  def __len__(self):\n","      return len(self.ids)"]},{"cell_type":"markdown","metadata":{"id":"zG6RyQ7PcDiH"},"source":["## Data production from previous model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sM3aOnrPcGK-"},"outputs":[],"source":["MODEL_NAME = \"Unet\"\n","# MODEL_PATH = model_weights_folder + f'{RUN_NAME + MODEL_NAME}.pth'\n","MODEL_PATH = model_weights_folder + 'vic_aug3Unet.pth'\n","DEVICE ='cuda'\n","\n","test_model = torch.load(MODEL_PATH)\n","\n","foreground_threshold = 0.5  # Threshold for determining foreground vs background"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRhEmiSIcLL_"},"outputs":[],"source":["PATH_TR_IMG_AUG_RAW = \"./data/data_train_augmented_vic2/raw/images/\"\n","PATH_TR_MASK_AUG_RAW = \"./data/data_train_augmented_vic2/raw/masks/\"\n","PATH_VAL_IMG_RAW = \"./data/data_validation_vic2/raw/images/\"\n","PATH_VAL_MASK_RAW = \"./data/data_validation_vic2/raw/masks/\"\n","PATH_TR_IMG_AUG = \"./data/data_train_augmented_vic2/images/\"\n","PATH_TR_MASK_AUG = \"./data/data_train_augmented_vic2/masks/\"\n","PATH_VAL_IMG = \"./data/data_validation_vic2/images/\"\n","PATH_VAL_MASK = \"./data/data_validation_vic2/masks/\"\n","\n","#change paths for the training and validation datasets depending on wether we want data augmentation or not\n","if PARAMS[\"DATA_AUGMENTATION\"]:\n","  training_path_img = PATH_TR_IMG_AUG\n","  training_path_mask = PATH_TR_MASK_AUG\n","  validation_path_img = PATH_VAL_IMG\n","  validation_path_mask = PATH_VAL_MASK\n","else:\n","  training_path_img = PATH_TR_IMG_AUG_RAW\n","  training_path_mask = PATH_TR_MASK_AUG_RAW\n","  validation_path_img = PATH_VAL_IMG_RAW\n","  validation_path_mask = PATH_VAL_MASK_RAW\n","\n","#create training and validation datasets\n","eval_train_dataset = Dataset2(\n","    training_path_img,\n","    training_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=['road'])\n","\n","\n","valid_dataset = Dataset2(\n","    validation_path_img,\n","    validation_path_mask,\n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    classes=[\"road\"],\n",")\n","\n","#create the loaders for both datasets\n","eval_train_loader = DataLoader(eval_train_dataset, batch_size=8, shuffle=False)\n","valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"sXoEtV3XbjtS"},"source":["## Yo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1702142380792,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"WcSEh35kl24h","outputId":"03ec0044-83e8-4c6b-ac39-0db61da35f2e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./submissions/submission_vic_aug3/'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["submission_folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":14,"status":"error","timestamp":1702142869023,"user":{"displayName":"Freedent Goutfraise","userId":"08736496591323178161"},"user_tz":-60},"id":"HIwnIEGChGpR","outputId":"a433b9a5-fec4-403a-8c83-808f1fa05ef4"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-19bac628ef3b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Iterate over the DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-349eef04465b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m               \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m               \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_each_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     )\n\u001b[1;32m    117\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, img, **params)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_apply_fns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_to_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: to_tensor() got an unexpected keyword argument 'cols'"]}],"source":["import os\n","import torch\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from torchvision.transforms.functional import to_pil_image, to_tensor\n","from PIL import Image\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","test_model = test_model.to(DEVICE)\n","\n","# Parameters for saving images\n","output_folder_images = \"./data/train_dl2/img/\"\n","output_folder_masks = \"./data/train_dl2/mask/\"\n","os.makedirs(output_folder_images, exist_ok=True)\n","os.makedirs(output_folder_masks, exist_ok=True)\n","\n","# Iterate over the DataLoader\n","for i, (image, mask) in enumerate(eval_train_dataset):\n","    with torch.no_grad():\n","        test_model.eval()\n","        # Move input to the device\n","        input_tensor = image.to(DEVICE)\n","        logits = test_model(input_tensor)\n","        # Apply sigmoid to get probabilities\n","        probabilities = torch.sigmoid(logits)\n","        # Squeeze to remove unnecessary dimensions\n","        probabilities = probabilities.squeeze(0).squeeze(0)\n","        # Apply threshold to the probabilities to binarize\n","        prediction_binarized = (probabilities < foreground_threshold).float()\n","\n","        # Convert the binarized prediction to a PIL image\n","        prediction_pil = to_pil_image(prediction_binarized)\n","\n","        # Resize the PIL image to 608x608\n","        prediction_pil_resized = prediction_pil.resize((608, 608), Image.NEAREST)\n","\n","        # Save the image and mask\n","        image_num = i + 1  # Assuming 'i' starts from 0\n","        image_filename = f\"img_{image_num:03d}.png\"\n","        mask_filename = f\"mask_{image_num:03d}.png\"\n","\n","        prediction_pil_resized.save(os.path.join(output_folder_images, image_filename))\n","        to_pil_image(mask).resize((608, 608), Image.NEAREST).save(os.path.join(output_folder_masks, mask_filename))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28peePjimMVU"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Ff0LsIB4QLCk"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}